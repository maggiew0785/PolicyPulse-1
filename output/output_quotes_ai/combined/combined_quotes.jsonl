{"entries": [{"quote": "Their method of control is through cyber-space, mobile devices, etc and they are basically replacing the human essence with AI software with encrypted spyware, which can only be accessed from the main server.", "summary": "The quote discusses concerns about AI taking over by using encrypted spyware, which poses data privacy risks as it monitors and replaces human actions through cyber tools."}, {"quote": "There is facial recognition software on every camera on every street which has multiple two-way swivel heads. As a result; there is no blind spot. So, walking on the street is out.", "summary": "This statement highlights privacy concerns regarding the pervasive use of AI-driven facial recognition technology, suggesting there are no privacy-safe spaces in public."}, {"quote": "There are also drones which patrol the ground and the skies making sure everyone checks out with the information in the database. Same database which social media has been feeding for years with the concise information of every human being on the civilized planet.", "summary": "The quote raises issues about data privacy related to AI, mentioning how social media has contributed vast amounts of personal information to databases that are now monitored by AI-powered drones."}], "source_id": "5878s0"}
{"entries": [{"quote": "The most important change to make in the economy in response to self-learning AI is to restore the ownership of all data to the subject of the data. Only summarized data that cannot be reprocessed to identify the person should belong to the collector.", "summary": "The quote emphasizes the need for data ownership to remain with individuals, not collectors, and suggests using only anonymized summarized data that cannot identify individuals."}, {"quote": "Every time personal data is used, the subject of that personal data should be paid approximately a AU$1.00 fee. This includes every financial record, government record used by non-government entities, the location of a vehicle, mobile, or other devices, and similar information. Any use of summary data that was developed without payment would incur the fee.", "summary": "The author advocates for compensating individuals every time their personal data is used by third parties, highlighting an economic model for data privacy in AI usage."}], "source_id": "6tpn1s"}
{"entries": [{"quote": "Saavy Relations- Importance & Impact of Artificial Intelligence. Societies will face challenges in realizing technologies that benefit humanity instead of destroying and intruding on the human rights of privacy and freedom of access to information.", "summary": "The post discusses the potential challenges posed by AI technologies, specifically highlighting concerns about AI intruding on human rights, including data privacy and freedom of information."}], "source_id": "7eggse"}
{"entries": [{"quote": "I'm not going to lie, we should be worried but not because of AI overthrowing humanity (at least not for a while) but how companies and governments will and are using AI.\n\nThe value of a person is moving from that of worker to that of a data point.", "summary": "A user is expressing concerns about how AI is being used by companies and governments to treat individuals as data points, raising data privacy and ethical issues."}], "source_id": "7h55zw"}
{"entries": [{"quote": "When you walk into Walmart, their AI system immediately begins tracking you, analyzing each customer through facial recognition and comparing your MAC address from your phone to their database. They keep track of your purchases and their Roll back program is not designed to give you the best price, it's to make the most profit.", "summary": "A user's concern about Walmart's AI system tracking customers through facial recognition and phone MAC address, raising concerns about privacy and data usage."}], "source_id": "7gb5t6"}
{"entries": [{"quote": "This is an absolutely beautiful idea in a horrifying way - a swarm of drones making mostly autonomous decisions about how to collect data, all while feeding back their collections to multiple locations on the ground. How do you provide oversight of the swarm, while still not allowing a hacker to gain control of the swarm?", "summary": "Concerns are raised about the privacy implications and security risks of autonomous drone swarms collecting data, with specific mention of the challenges in preventing unauthorized access or hacking."}], "source_id": "7l636l"}
{"entries": [{"quote": "My bet is that the augmented mind becomes the new norm, terrific wars are fought initially, and humanity makes inedible gains at the cost of all privacy and individual thought.", "summary": "The commenter predicts that in the future, enhanced minds will become standard, but this progression will come with significant wars and the loss of privacy and individuality."}, {"quote": "Just like many of us have access to cell phones in our pocket, imagine having access to a machine with superhuman logic to plan, hack, solve world hunger, win the Nobel peace prize, get rich, attempt to live longer, attempt to kill off an entire race, attempt to commit suicide and take the human race with them, or any other whim or desire you may have good or bad.", "summary": "The comment highlights concerns about widespread access to highly intelligent AI, which could be used for various purposes, including hacking and other potentially harmful actions, thereby posing significant privacy and safety risks."}], "source_id": "6vsu3x"}
{"entries": [{"quote": "Also don't miss out on \"We may share your information with third parties\" on their privacy policy. Ok, so you decided to delete your reply to my comment above. here's what you replied:\n\n\"What's the value in that comment? Everything we do is encrypted to the max. We don't use your information for any commercial purposes outside of what we do. Tell me what website does not share personal information with third parties when they sell you add all day?\" First of all you cannot justify your intrusive policies just because other website/services do the similar.\n\nI don't see the word \"encrypted\" anywhere on your Privacy Policy. Also simply, I don't believe you.\n\nUnless what you do is selling personal information, not just to advertisers, but other third parties that they want to improve their Machine Learning algorithms.", "summary": "A user criticizes a service for potentially sharing personal information with third parties and questions the service provider's claim about data encryption and non-commercial use of user data outside their services."}, {"quote": "I'm just gonna quote some lines from your Privacy Policy and ask, why the fuck would you do/need that for?\n\n\"...we may collect your precise location data...we may also collect the precise location of your device when the app is running in the foreground or background.\"\n\n\"...we may access and store names and contact information from your address book for other purposes described in this Statement.\"\n\n\"...In some cases we do this through the use of cookies, pixel tags, and similar technologies that create and maintain unique identifiers.\"\n\n\"We may collect information about your mobile device, including unique device identifier, advertising identifiers, serial number, device motion information, and mobile network information.\n\n\"...we receive call data, including the date and time of the call or SMS message, the parties\u2019 phone numbers, emails and the content of messages between parties. Again, not encrypted\"\n\n\"...we collect server logs, which may include information like device IP address and the third-party site or service you were using before interacting with our Services.\"", "summary": "A user questions the necessity and purposes behind collecting and storing various types of sensitive data as outlined in a service's privacy policy and points out the lack of encryption for this data."}, {"quote": "\"Send you communications we think will be of interest to you, including information about products, services, promotions, news, and events of Instantgo and other companies...or other promotion entries and fulfill any related awards: Personalize and improve the Services, including to provide or recommend features, content, social connections, referrals, and advertisements.\"\n\n\"With third parties to provide you a service you requested through a partnership or promotional offering made by a third party or us;\"\n\n\"With your employer (or similar entity) and any necessary third parties engaged by us or your employer...\"\n\n\"With vendors, consultants, marketing partners, and other service providers...\"\n\n\"We may allow others to provide audience measurement and analytics services for us, to serve advertisements on our behalf across the Internet, and to track and report on the performance of those advertisements.\"\n\n\"Additionally, disabling our app\u2019s collection of precise location from your device will not limit our ability to derive approximate location from your IP address.\"", "summary": "A user highlights several sections from a service's privacy policy, revealing extensive data sharing with third parties, including employers and marketing partners, and the ability to track user location even when location settings are disabled."}], "source_id": "6m0tmi"}
{"entries": [{"quote": "Personally, I want to have more say about the legal and ethical standards that my government will use in the future than just trusting them when they assure me that their AI systems now make decisions trained with the best advice available by the most trustworthy giant corporations and least invasive military and law enforcement agencies.", "summary": "The commenter expresses a desire for greater involvement in setting legal and ethical standards for government AI systems rather than simply trusting assurances from corporations and military/law enforcement agencies about the training and rationality of these systems."}], "source_id": "8kosjr"}
{"entries": [{"quote": "Moreover, although I recognise that approximation is unavoidable, one question I keep asking is what is the degree of approximation we should accept when using data that will produce an actionable insight on real people.", "summary": "The author expresses concern about the acceptable level of approximation in data that AI systems use to make decisions about individuals, highlighting a key data privacy and ethical issue."}], "source_id": "8p9j2l"}
{"entries": [{"quote": "From a criminal/ethical perspective, imagine a criminal activity is executed by the AI on behalf of a user (ie: calls a drug dealer, orders a back-page prostitute, etc). Would prosecutors be able to access the original instructions that were given to the AI bot?", "summary": "The quote raises ethical concerns about AI bots potentially being used to carry out criminal activities and the privacy implications of accessing AI instructions for legal purposes."}, {"quote": "In the end, this would at least add another layer of anonymity to online crime where criminals already use encrypted IP addresses & anonymous profiles. I assume it only works via your Google profile but you could easily set up one and call instructions in from a burner phone / emulator.", "summary": "The quote highlights the risks of increased anonymity for criminals using AI systems, complicating efforts to track and prosecute offenders."}, {"quote": "And what about over-the-phone banking? They record your response of \u201cyes\u201d to approve an ACH transfer as the equivalent to your signature/acceptance of terms.", "summary": "This quote discusses the privacy and security implications of using AI for sensitive tasks such as banking, emphasizing the potential for fraudulent approvals."}, {"quote": "As technology advances, so too will legislation. Sure, but not until the early adopter scammers/criminals make their money first. The legal system doesn\u2019t move as fast as criminals.", "summary": "The quote reflects concerns that legislation protecting data privacy might lag behind technological advancements, allowing early adopter criminals to exploit these gaps."}], "source_id": "8i57bu"}
{"entries": [{"quote": "For example some conceivable outcomes could be the enslavement of most or all of humanity, nuclear winter, loss of individual rights. It doesn't take much imagination to think of a very long list of devastating scenarios, and many of these seem very probable given our current path...", "summary": "The commenter discusses various extreme scenarios resulting from AI misuse, including the loss of individual rights, which implies a concern for data privacy among other issues."}], "source_id": "8s7koe"}
{"entries": [{"quote": "first and foremost we seem to be so lazy that we fail to read the privacy statements and terms and conditions that we tend to scroll to the bottom and hit accept. not realizing what we are consenting to and agreeing with.", "summary": "The author expresses concern that people do not read privacy statements and terms and conditions, unknowingly giving consent to intrusive data practices."}, {"quote": "our smart phones and being utilized in the background of our phones without us being aware", "summary": "The author asserts that smartphones are being used for data collection and manipulation without users' awareness."}, {"quote": "I understand why people would be suspicious of both smart phones and AI in general. Even mainstream leaders in their respective fields like Elon Musk and Stephen Hawking have warned about the potential dangers of AI.", "summary": "A commenter acknowledges the public's suspicion of AI and smartphones, highlighting warnings from notable figures about AI's potential dangers."}], "source_id": "8r8499"}
{"entries": [{"quote": "Additionally, given that companies and governments are increasingly using computer vision algorithms to detect people\u2019s intimate traits, our findings expose a threat to the privacy and safety of gay men and women.", "summary": "The study highlights a significant privacy concern, indicating that AI algorithms used to detect personal traits can pose a threat to the privacy and safety of individuals, particularly LGBTQ+ communities."}], "source_id": "9c47cq"}
{"entries": [{"quote": "The big AI had access to Five Eyes\u2019 ECHELON, which was initially made to surveil Russia and the Eastern Bloc but which emerged to watch billions of private communications worldwide on the planet and from satellite transmissions.", "summary": "The quote discusses how a powerful AI developed under the Five Eyes alliance gained access to global surveillance systems, raising data privacy concerns due to its capability to monitor billions of private communications."}, {"quote": "The Palantir AI has potential connections to DarkNet hackers through Thiel\u2019s MIT/Stanford network, shared by Aaron Swartz, as well as access to the largest surveillance on the planet.", "summary": "This statement highlights the privacy risks associated with Palantir AI, expressing concerns about its connections to hackers and extensive access to global surveillance data."}], "source_id": "95qoyy"}
{"entries": [{"quote": "It might find us through some type of footprint we leave behind in the code to its virtual reality we put it in. There is no way to create a program without leaving some type of trail back to us.", "summary": "Discusses the potential risk that an AI could trace back to the real world through identifiable traces in its virtual environment, raising concerns about data privacy and unintentional exposure."}], "source_id": "9c09r1"}
{"entries": [{"quote": "if we replace all politicians and power seeking morons with neutral and caring robots/AI (whose only purpose in life is to serve people and make them happy) before we replace everything else, then we wouldn't have problems with issues such as privacy concerns or malicious use of accumulated data.", "summary": "The commenter suggests that replacing human politicians with AI that genuinely cares for people could mitigate privacy concerns and prevent the malicious use of accumulated data."}], "source_id": "9eobgu"}
{"entries": [{"quote": "Injected nano WiFi routers embedding themselves in our brains, if gone mainstream, could give rise to something akin to a hive mind.", "summary": "The commenter discusses the potential privacy concerns and risks associated with injecting nano WiFi routers into human brains, which could lead to privacy intrusions on a massive scale."}, {"quote": "I'm terrified that, little by little and day by day, people are working toward that... chipping away at rights, expression, individual humanity, etc. until it's nearly gone.", "summary": "The commenter expresses fear about the gradual erosion of individual rights and privacy due to the concentration of power, potentially exacerbated by AI technologies."}], "source_id": "9cg1qh"}
{"entries": [{"quote": "Imagine how much control something can have over people if everything is implanted in them. And that\u2019s all coming in the next 20 years if he correct! Fucking amazing.", "summary": "This quote discusses the potential control and privacy implications of AI technologies, particularly in the context of implants and advanced AI integration in the future."}], "source_id": "9ina2q"}
{"entries": [{"quote": "In effect, if it could be done right now, it probably would've been, so most likely Human AI can't exist with our present technology. Still, I'm aware that many experts predict it will be possible within the next 10-15 years, so surely within our lifetime.", "summary": "Discussion on the technological limitations of current AI and the prediction that human-level AI might be possible in the next decade or so."}, {"quote": "We all need to be cognizant and acknowledge that AI means a lot of things to a lot of different people. The 'ai effect' is an example of evolving AI. the question is where's the balance with it all and what responsibility do we have as humans to potentially do something about it??", "summary": "A general reflection on the evolving nature of AI and the responsibility humans have in managing its implications."}], "source_id": "9ev2b5"}
{"entries": [{"quote": "Right now with only our available technology we can collect thousands of information about each person with a phone and Access to the internet. But to get more information we will need people to monitor each individual's information and try to connect the dots to know more details about that individual's life. But with AI it is different. The AI can monitor each individual without a problem and the way it will connect the dots will be more accurate. And what scares me is that it could go beyond that and tell you things about that individual that exceed what seems possible now, like telling you not just what they are thinking about, but what they will be thinking in the future and what actions they will take before they themselves know that they are going to do them. As facial recognition and digital storage become better and they are able to track millions in real time and keep it indefinitely, you will have no privacy. A person's life will be an open book.", "summary": "The commenter expresses deep concerns about AI's ability to monitor individuals closely and accurately, predicting their thoughts and actions, which poses significant threats to personal privacy."}], "source_id": "9jkdmf"}
{"entries": [{"quote": "\"AI is really important, but we have to be concerned about it.\"", "summary": "Google CEO Sundar Pichai emphasizes the importance of being cautious with AI, implying that while it holds great potential, there are inherent dangers that need to be addressed, including those related to data privacy."}], "source_id": "9o3zan"}
{"entries": [{"quote": "But big picture imagine the implications of a government running all passport photos against known criminals and making a database of possible criminals based on it. I think it's probably recording all you do under your name and depending on what you do and where you are, who you talk to, who they talk to etc.", "summary": "Concerns about government surveillance using AI to track and profile citizens based on their activities, potentially infringing on privacy rights."}, {"quote": "Then maybe to the actual photo they should attach info like a personality profile so that the AI can observe various types of profiles and face expression.", "summary": "Suggestion to attach personality profiles to photos for AI to analyze, raising significant privacy concerns regarding the extent of personal data collection and its implications."}], "source_id": "9r9gh9"}
{"entries": [{"quote": "What is much more concerning to me is the overuse of AI in so many different areas before we properly understand what kind of bias we are putting into these systems via data or the consequences of using such a biased system to make very important decisions (insurance, credit scores, criminal justice decisions, profiling based on race in government, mission critical systems, and many other areas).", "summary": "A user expresses concern about the premature use of AI in critical areas without fully understanding the biases in data and the potential consequences, especially regarding important decision-making processes."}], "source_id": "9sjh1v"}
{"entries": [{"quote": "You need to verify if they are doing it as a service (plans to charge a fee to their users) or just collecting data to sell to other companies. Read their Privacy Policy, if it has in any way mentioned that they might sell your data, refrain.", "summary": "The commenter advises checking whether the website plans to charge users directly or collect and sell their data to other companies, emphasizing the importance of reading the Privacy Policy to avoid potential data privacy issues."}, {"quote": "As of now, there is no such technology available that can keep you 'alive' forever (what they are offering is just a database of your memories) and this is just a way ensuring that when that kind of technology (something in terms of brain imitation) arrives you have your history arranged for you, but the thing is, a simple habit of Diary writing is just as same as what any site can offer right now.", "summary": "The commenter points out that current technologies can only store data rather than achieving virtual immortality and implies that maintaining personal diaries could offer similar benefits without the privacy risks associated with data storage services."}], "source_id": "9rlfn6"}
{"entries": [{"quote": "Was relinquishing our privacy worth it in the long run for the AI we have today?", "summary": "The user is questioning whether sacrificing privacy has provided enough benefits in terms of the advancements in AI available today."}, {"quote": "Or will it be worth it for the AI we have in 20 years?", "summary": "The user extends their query to the future, wondering if the privacy trade-offs made today will be justified by the AI developments in the coming decades."}], "source_id": "9txvvd"}
{"entries": [{"quote": "Why are we allowing this as a society? As a society? As a species. Nobody questioned social media back in 2000s we are observing the consequences now, this technology is a reality and will be put out to market soon, and we have no idea about what will happen next. Why don't we as a species as humans take two steps back and look at the big picture.", "summary": "The commenter expresses concern about Google's new AI technology, drawing parallels to the unchecked rise of social media and its unforeseen consequences, and calls for society to take a step back and consider long-term impacts."}], "source_id": "9zd11m"}
{"entries": [{"quote": "On the other hand when I was single and registered at some online dating site and then Facebook kept showing ads on my profile - join academic singles, speed dating etc. that was less pleasant especially when some colleague went by and saw it.", "summary": "A user shares their personal experience with AI-powered targeted advertising on Facebook, highlighting the privacy concern of ads revealing personal information in public or professional contexts."}, {"quote": "So it has some good sides and bad sides - more options, less privacy. I personally don't mind and I believe the pros outweigh the cons. Also, now you have more control over your private information, so you have better means to opt-out of this if you want which I think is good (but I would not do it, e.g. on YouTube cause I would not like to lose my personalized profile).", "summary": "A user acknowledges both the benefits and privacy drawbacks of AI in advertising, noting that while they value personalized recommendations, they are aware of the reduced privacy and the available opt-out options."}], "source_id": "a52htj"}
{"entries": [{"quote": "Wearing masks perhaps come a reality with so much surveillance everywhere. In Venice, there was a time when people did wear masks to protect their identity, just like the picture, and this turned into the Venice carnival today. But yeah, it's possible to go back in time to previous ways to protect privacy that people used centuries ago. Just a simple stylish mask. :)", "summary": "Discusses the history of wearing masks to protect privacy in Venice and considers the possibility of using masks again due to increasing surveillance."}, {"quote": "They will just use Gait Analysis, so you will need to wear long dresses with fake knees lol.", "summary": "Mentions the use of gait analysis as a potential way to bypass traditional privacy measures like wearing masks."}], "source_id": "a5g6b7"}
{"entries": [{"quote": "I would have loved to build something that recognizes the person entering the phone booth, based on people checking into the event on Facebook, but I think that's a dangerous route in these GDPR times.", "summary": "The author expresses concern about building an AI system that recognizes individuals based on their Facebook check-ins, due to the stringent data privacy regulations outlined in the GDPR."}], "source_id": "agjg7h"}
{"entries": [{"quote": "As if the amount of information Facebook has and how they have used it. This seems scary in comparison.", "summary": "The user expresses concern about the privacy implications of the AI technology by comparing it to the extensive data collection practices of Facebook."}, {"quote": "I can see this being nice if it was a standalone app for some one to use locally or a corporate app for a company to mine their own data, but allowing a third party access to my data...... Certainly just like any other social media apps.", "summary": "The user highlights their unease about giving a third-party app access to their data, likening it to the privacy issues associated with social media platforms."}], "source_id": "aflr46"}
{"entries": [{"quote": "He wants your data free so he can sell stuff.", "summary": "A comment expressing skepticism about the Salesforce CEO's statement, suggesting it might be a ploy to access and sell user data, highlighting a data privacy concern."}], "source_id": "ajntcp"}
{"entries": [{"quote": "Your birth Certificate to engage on your behalf in the interest of allowing Allies(corporations) to gain access to your estate by fraud and deception. Splitting it over cloud infrastructure, minimizing single point of blame, not failure. So let it be told.. They will Abuse your information, sell it off, just like they already do.", "summary": "The post discusses a concern that cloud-based technologies and digital identities might be manipulated by corporations to gain unauthorized access to personal information, leading to abuse and commercial exploitation of the data."}, {"quote": "People will complain, beg their governments to do something about it, information is being sold off, they are being hacked, attacked, ID theft etc\u2026", "summary": "The author anticipates public outcry over data privacy breaches and identity theft due to unauthorized collection and selling of personal information by third parties."}, {"quote": "Here citizens of Rome the only way to protect your information is to Accept to become part of the machine, Install this TPM module (yeah, it doesn\u2019t hurt, very unobtrusive, everyone\u2019s doing it) PLUS you earn free govt credits (Domestication Points) OR WE WILL USE THAT INFO AGAINST YOU, destroy you.", "summary": "The writer hypothesizes a dystopian solution where individuals are forced to install a TPM module to protect their information, facing coercion to integrate with a highly regulated system under threat of data misuse."}, {"quote": "We will be allowed to monitor and correct our information ONLY if installed with a TPM module hooked up to a massive federation server. In doing so, we sign over any humanity we have left and leave the bad guys in charge of all things internet.", "summary": "The author expresses concerns that integrating biometric security measures such as TPM modules for data privacy would lead to a loss of personal autonomy and increased control by powerful entities over internet activities."}, {"quote": "Does this TPM contain a 3D face scanner? If not, what happens if the device gets stolen? Will the thief see my personal data and be able to identify to third parties as myself?", "summary": "A commenter raises practical concerns about the security of TPM modules, questioning the implications of device theft and unauthorized access to personal data."}], "source_id": "9stipl"}
{"entries": [{"quote": "There are things we can do (and imagine doing) with AI that we really don\u2019t want. Look up China\u2019s social credit system, for example. Much of that fiasco is made possible because of different applications of AI. And the social credit system is a government use.", "summary": "The quote references the use of AI in China's social credit system as an example of the potential negative implications and data privacy concerns associated with AI technology."}], "source_id": "anb27b"}
{"entries": [{"quote": "We can also imagine the application of these models for malicious purposes, including the following (or other applications we can\u2019t yet anticipate): Generate misleading news articles, Impersonate others online, Automate the production of abusive or faked content to post on social media, Automate the production of spam/phishing content", "summary": "The quote discusses potential malicious uses of advanced AI models, such as generating fake news, online impersonation, abusive content, and spam, all of which pose significant data privacy risks."}], "source_id": "aqu0nf"}
{"entries": [{"quote": "the only threat would be the hackers with bad intention that could take over those AI to harm people.", "summary": "The discussion mentions the risk of malicious hackers potentially taking control of AI systems to cause harm, raising a significant data privacy and security concern."}], "source_id": "aup327"}
{"entries": [{"quote": "OpenAI, an nonprofit research company backed by Elon Musk, says its new AI model, called GPT2 is so good and the risk of malicious use so high that it is breaking from its normal practice of releasing the full research to the public in order to allow more time to discuss the ramifications of the technological breakthrough.", "summary": "OpenAI decided not to release the full GPT2 model due to concerns about its potential misuse, highlighting the ethical concerns and risks related to data privacy and the responsible dissemination of powerful AI technologies."}, {"quote": "How do we know that this article wasn\u2019t written by GPT2? And it wants us to think that it wasn\u2019t? Hmmm? Oh dear. Looks like authors and writers are out of a job.", "summary": "This comment humorously questions the authenticity of the article, reflecting underlying data privacy concerns about the inability to distinguish between human and AI-generated content."}], "source_id": "aqyong"}
{"entries": [{"quote": "Government AI used in this way is scary. We all want people who abuse the system to be caught, but there is also a great potential for the government to abuse their power.", "summary": "Concerns about government misuse of AI, including potential abuse of power, which raises issues related to data privacy."}], "source_id": "aw6lei"}
{"entries": [{"quote": "\u00ab The Internet was built with security as an afterthought, rather than a core principle. We\u2019re still paying the cost for that today \u2026 With AI, we should consider safety, security and ethics as early as possible, and bake these into the technologies we develop. \u00bb", "summary": "This quote emphasizes the importance of integrating safety, security, and ethics into AI development from the beginning to avoid the pitfalls experienced with the Internet's lack of initial security considerations."}], "source_id": "avwg1j"}
{"entries": [{"quote": "I do wonder if we as a society can afford to wait to work out all of the bugs of implementing non-biological intelligence into our government systems. There's the potential for a society that successfully implements it to existentially dwarf other societies at a rapid rate. The one that my mind immediately goes when thinking of this is China. They have been very quick to rise in regards to technology, and their social credit system and massively mass surveillance is already resembling what I would call a \"digital dictatorship\".", "summary": "This user expresses concern that waiting to solve data privacy issues in AI systems used by governments could allow less cautious societies to gain significant advantages, pointing to China's social credit system and mass surveillance as potential models of a 'digital dictatorship.'"}], "source_id": "avqlz5"}
{"entries": [{"quote": "Data protection is quite essential..", "summary": "A general statement emphasizing the importance of data protection."}], "source_id": "be49i0"}
{"entries": [{"quote": "Finally it will be conversational, in that as AI improves chatbots will become more and more common, allowing for live interaction with consumers. &gt;\texample of this is a personalized ad that asks you questions to create a unique to you ad\n\nIt really doesn't need to ask you anything. Google, Facebook, and Amazon are able to target ads very effectively just based on the data they collect from you using the internet.", "summary": "Discussion about how major companies like Google, Facebook, and Amazon collect extensive user data to effectively target ads, highlighting inherent data privacy concerns."}], "source_id": "bcbp10"}
{"entries": [{"quote": "Yes! We need the robot laws.. right now the only law out there is efficiency and profit for the actors controlling AI.", "summary": "Current AI regulations prioritize efficiency and profit, potentially overlooking ethical considerations and data privacy."}, {"quote": "If op was right it would backfire right now as innocent businesses, researchers, and hobbyists could potentially be prosecuted for cyber crimes under such a broad interpretation.", "summary": "There are concerns that broad AI regulations could unjustly impact benign users, including innocent businesses and researchers."}, {"quote": "This is what Facebook is doing, letting booth 5 run the joint. And they could solve this problem by confirming identity and tagging all unconfirmed entities as potential bots. They could solve their culpability with a feature that would take no more than a month to implement. But they don\u2019t. Funny how that works, eh?", "summary": "Facebook could address data privacy concerns by confirming identities and tagging unverified entities as bots but chooses not to."}], "source_id": "bgw0l5"}
{"entries": [{"quote": "More advanced technology = more monetary risks that bigger companies have in regards to hacking and privacy breaches. For example, the data of different users on Facebook can be sold if they get into the wrong hands.", "summary": "The quote discusses the increased risks of hacking and privacy breaches with the advancement of AI technology, highlighting the potential misuse of user data, such as on platforms like Facebook."}], "source_id": "bx6yao"}
{"entries": [{"quote": "Human Personal Data and social behavior are harvested from all kinds of platforms like online surveys or even simple hand phone games. With the help of AI, humans use psychological manipulation, entrapment techniques and fake news campaigns for political and financial gains. Instead of desired selected reference data, the AI scours the vast internet for related data and use them as reference.", "summary": "This quote expresses concerns about the misuse of AI to harvest personal data and social behavior for manipulative purposes, such as political and financial gains."}, {"quote": "How then the restrictions of unwanted data? Fake news or otherwise, one would need to employ another AI system to combat another AI system. The human can no longer effectively control or manage what can be seen or what cannot manually.", "summary": "The author discusses the difficulty in controlling unwanted data and fake news, highlighting the need for AI systems to regulate other AI systems due to the limitations of human management."}, {"quote": "The most common formula across all forms of technology is the quantum factor. Each advancement in technological advancement takes a shorter time to produce, better output efficiency and at a lower cost than its previous generation. The humans are playing catch up on its usage. Before one can get use to a format of a particular internet search engine, an automatic update comes along and make subtle changes... This would seem unthinkable but this is already happening. Not that the AI is protecting itself but an instruction inserted by humans to protect other humans.", "summary": "The quote raises privacy concerns related to AI's rapid advancements and constant updates which may introduce new risks or protect interests that are not transparent to users."}], "source_id": "bqtbth"}
{"entries": [{"quote": "Were we ever told why this happened? It's not like it's the only database around so it's not like Microsoft was defeating the world's evils. Seems like a pointless move?", "summary": "A user questions Microsoft's motivations behind deleting the face recognition data set and expresses suspicion about its effectiveness in addressing larger data privacy and ethical concerns."}], "source_id": "by4oi5"}
{"entries": [{"quote": "We should be terrified of self learning AI and our permanent mental and physical bonding with the internet. Anyone at the forefront of AI that doesn't think that doesn't know what they're talking about.", "summary": "Expresses a strong opinion on the dangers of AI, particularly regarding the permanent integration of AI with human consciousness and the internet."}, {"quote": "Imagine AI produced images designed to advertise certain products or agendas. Imagine that image designed by something 100x more intelligent than a human. It would be able to produce images that could effectively hypnotise the viewer into buying the product, or supporting a specific political party. We will have no control over it when it's built. It will just do and learn without input. Changing human thought without us realising because that's what the AI is designed to do.", "summary": "Raises concern about AI's potential ability to manipulate human thoughts and behaviors through advanced advertising techniques, highlighting a significant data privacy and ethical risk."}, {"quote": "Of course it will hopefully be designed to better the human race and the effectiveness of such a thing could have the consequences of reducing our ability to make REAL conscious decisions, uninfluenced by suggestive imaging or text.", "summary": "Mentions the ethical concern that even well-intentioned AI could diminish human autonomy and genuine decision-making by subtly influencing thoughts and actions."}, {"quote": "This isn't crazy talk. Laws need to be put in place restricting how AI can be used and created.", "summary": "Emphasizes the necessity for legal regulations to control the development and application of AI to prevent potential abuses and ensure ethical data use."}], "source_id": "bt6zde"}
{"entries": [{"quote": "It\u2019s so scary how advanced it is and how behind the law is. There are ethical guidelines out there and some privacy laws, but in my country they don\u2019t extend to machine learning.", "summary": "A user expresses concerns about the rapid advancement of AI surpassing current privacy laws and ethical guidelines, emphasizing the need for legal updates to encompass machine learning technologies."}], "source_id": "c0ieub"}
{"entries": [{"quote": "While big brands are thriving to get user data they need to perform better, there\u2019s always a risk (although it\u2019s quite minimal) this data may get into the hands of the wrong people. In all fairness, these companies are investing a lot of money and effort to protect it, so you don\u2019t have to worry.", "summary": "The commenter acknowledges the minimal risk of user data falling into the wrong hands, while also noting that companies invest heavily in protecting data security."}], "source_id": "c2er24"}
{"entries": [{"quote": "Because it is not economic to analyze them for the whole human society. After that if we keep grow them, since we don't have enough brains to understand them fast enough, to see their evolution direction and to respond, We are certainlly give up our decision of our welfare to AI. It is like astrology or blind gambling.", "summary": "This quote highlights concerns about the economic feasibility and human capacity to continually analyze and understand AI systems as they evolve, ultimately suggesting that humans might lose control over their welfare to AI if we can't keep up."}, {"quote": "AI now we release and grow on server is a little complex but still with clear purpose we can figure out. Ten years later, although they appears to be driving AIs or tumor-scanning AIs, what they really are, who knows? unless we stop them and analyze them.", "summary": "The quote expresses concern about the future evolution of AI, emphasizing that while current AI systems are understandable, future iterations might become opaque and potentially dangerous without continuous oversight."}, {"quote": "To thrive, we need take our own decison rather than give up to unsuperviseable AI. Based on your understanding, AI is a kind of pattern we CAN'T CONTROL IF YOU SEE IN A LAGER TIME SCALE.", "summary": "This quote underscores the need for human supervision of AI development, cautioning that AI systems could become uncontrollable and pose risks if left unsupervised over long periods."}, {"quote": "Or we get out and stop ai after that, this is a very ideal situation. On my understanding, AI is more than patterns that we can not control. They're parasites with better brains living on electricity in our tools computers that can gain their independence by taking control of our manufacturing facilities as if we don't have enough brains to supervise their action.", "summary": "The quote suggests that AI could evolve into autonomous entities capable of taking control of critical infrastructure, emphasizing the importance of maintaining oversight to prevent such scenarios."}], "source_id": "bwmao9"}
{"entries": [{"quote": "Depending on how the application/server creates logs, it may also be possible to create some \u2018home-brew\u2019 scripts to parse those logs and alert you of any suspicious input. There are additional security concerns if that\u2019s the route one would take - whatever goes in the forms will live in clear text in your logs - if this webpage served thousands of users, their form inputs would be easily readable by the technical team that maintenances the server. Food for thought.", "summary": "Discusses the privacy risks associated with storing form inputs in clear text within server logs, highlighting how technical team members could easily read sensitive user data."}], "source_id": "c2wfpt"}
{"entries": [{"quote": "I think the main conflict in personalized advertising using consumer data, is that it almost never really benefits the consumer. It is a tool for generating profit for the companies using it, through effectiveness.", "summary": "The user expresses concerns about personalized advertising focusing on company profits rather than consumer benefits, highlighting privacy and ethical concerns."}, {"quote": "Now, the main issue is that every single one of these solutions rely on server side data collection. A company agrees to use a solution and implements a solution script on their web shop/page. The data is sent to a log file and is analyzed and sent to a Google or Adobe data base. From there companies can see what is happening on their own respective domains. Not what is happening on competitor domains.", "summary": "The user explains how personalized marketing relies on server-side data collection and highlights privacy concerns related to data being collected and stored by companies like Google and Adobe."}, {"quote": "To put it short this would mean three very important things: 1) that Black Friday, Christmas sales, Summer sales and all that crap, is over... Sales is going to die as a concept. The whole concept of a sale, is a concept of intransparency. You bite, because you think it is a good deal. The AI does not care. AI will be machines dealing with machines.", "summary": "The user theorizes that AI advancements will lead to the end of traditional sales as AI will ensure transparent and efficient purchasing processes, which raises implications for data transparency and consumer privacy."}, {"quote": "What will happen, is that data collection and ownership in the future will reside with the consumer. An AI will do all your work for you, based upon your data compared to the rest of the internet user groups behavior. It will help you save money, make decisions and create quality in finding relevant products and solutions. Completely transparently. On your behalf and not companies behalf.", "summary": "The user envisions a future where data collection is controlled by consumers rather than companies, with AI systems representing consumers and ensuring transparent, user-focused data usage."}], "source_id": "c3sojd"}
{"entries": [{"quote": "This technology could be used in bad ways. Once technology can understand us, there will be repercussions. That time is soon and we all need to be preparing. Social profiling based off of a merit system already occurs in China. Facebook is also a huge system of social profiling, although not as outright as China's one.", "summary": "The author expresses concerns about the negative implications of AI technology's ability to understand humans, such as social profiling and privacy invasion, giving examples of China's merit system and Facebook's profiling practices."}, {"quote": "Keeping journals yourself and allowing me to scan them will teach me more about you.", "summary": "The author mentions a potential privacy concern where AI systems could scan personal journals to learn more about individuals, raising issues around personal data security and privacy."}], "source_id": "ca51nj"}
{"entries": [{"quote": "Others have speculated that Face App may use data gathered from user photos to train facial recognition algorithms. This can be done even after the photos themselves are deleted because measurements of features on a person\u2019s face can be extracted and used for such purposes.", "summary": "Speculation about Face App potentially using user photos to train facial recognition algorithms even after the photos are deleted, raising privacy concerns."}, {"quote": "Privacy advocate Pat Walshe pointed to lines in the Face App\u2019s privacy policy that suggested some user data may be tracked for the purposes of targeting ads. The app also embeds **Google Admob, which serves Google ads to users.** Mr Walshe told BBC News this was done 'in a manner that isn\u2019t obvious' and added: 'That fails to provide people with genuine choice and control.'", "summary": "Privacy advocate highlighting that Face App's privacy policy suggests user data may be used for targeted advertising, raising concerns about lack of transparency and user control."}, {"quote": "When something is free, your info is where you pay with... be careful people", "summary": "A user warning others that free services often require payment through personal information, advising caution regarding data privacy."}], "source_id": "cf4flq"}
{"entries": [{"quote": "Virtually every major people-facing company is now employing the tools of machine learning to gather information on its customers, and seeking to exploit their data for commercial advantage. There is nothing inherently wrong or sinister about this process, but what alarms many observers is how the tools of machine learning now make it possible for individuals to have enormous power, far more than any king or queen ever had in human history. Machine learning makes this possible.", "summary": "The quote discusses concerns about data privacy in the context of AI. Specifically, it notes how the widespread use of machine learning by large companies to gather and exploit customer data can result in individuals amassing unprecedented power."}, {"quote": "A significant concern with using machine learning on global scales are issues, not just with privacy, but also of fairness. Machine learned models will reflect biases inherent in the data, and there are well documented cases of gender and racial biases in machine learning systems that are causing alarm. Machine learning is used to learn face recognition models, and there\u2019s plenty of reason to be cautious in overly relying on such models.", "summary": "This quote highlights risks related to data privacy and fairness in AI. It emphasizes concerns about inherent biases in machine learning models which can influence decisions and impact privacy and ethics, particularly in systems like facial recognition."}], "source_id": "ch6wwk"}
{"entries": [{"quote": "Does it store your face on their cloud server making it their property? Oh really? That\u2019s the standard procedure in all cloud services offered for free!, you should read terms. Data belongs to the beast", "summary": "A user is concerned about whether the app stores selfies on a cloud server and discusses the standard procedure in free cloud services, implying issues with data ownership and privacy."}], "source_id": "cnn10s"}
{"entries": [{"quote": "But how will they justify having workers listen in on your intimate moments? /s", "summary": "A sarcastic comment highlighting privacy concerns over the potential of AI assistants like Alexa to have their neural models run on-device while potentially allowing access to intimate user interactions."}], "source_id": "cpt58j"}
{"entries": [{"quote": "Better yet, turn off Google assist and don't ever buy \"smart\" anything. The fact that my phone always shows adverts of things I was JUST talking about makes me super anxious! It may be by chance but it may be something a little more creepy haha! Thanks for the tips!!! Implemented (and unplugged)", "summary": "A user expresses anxiety and concern over potential data privacy issues with AI, mentioning that their phone displays advertisements related to recent conversations, suggesting possible eavesdropping."}], "source_id": "d6iu3z"}
{"entries": [{"quote": "Too bad its a huge privacy nightmare", "summary": "A user expresses concern that the AI-based grammar tool, Grammarly, poses significant privacy risks."}], "source_id": "dgclzx"}
{"entries": [{"quote": "https://www.forbes.com/sites/kashmirhill/2014/06/28/facebook-manipulated-689003-users-emotions-for-science/#500369f3197c This was discussed 8yrs ago. Back then it sounded exotic and powerful. Today there are thousands who could train a model to be a nuisance online.", "summary": "A linked article exposing how Facebook manipulated users' emotions years ago, highlighting concerns about advanced AI's ability to exploit and manipulate user data on social media platforms."}], "source_id": "dgoe9s"}
{"entries": [{"quote": "I don\u2019t think it will be AGI that will be the problem per se, but anything it can connect to that has the ability to cause harm. One technique I was thinking about is leaving a critical chip exposed from shielding solutions in robotics to permit a microwave gun to destroy it and disable the robot. Leaving any of the control circuitry exposed risks remote interfacing and hijacking.", "summary": "The commentator discusses the potential risks of artificial general intelligence (AGI) connecting to systems with harmful capabilities and mentions concerns about the vulnerability of control circuitry to remote interfacing and hijacking, highlighting data privacy and security implications."}], "source_id": "dh5ssl"}
{"entries": [{"quote": "When I believe is best for the human race, I am talking about keeping us healthy, mentally and physically. Ensuring that our planet and environment is healthy. We can input those in as parameters. AI does what we tell it. A psychologist can train it to treat mental trauma, it can give us new information, it can monitor our brain to see if we are happy and engaged, etc. It can be used for the opposite and destroy our well being.", "summary": "Discusses the dual potential of AI, including its use in personal health monitoring and mental health care, with an acknowledgment of the risk it poses to well-being if used unethically."}], "source_id": "dgox1e"}
{"entries": [{"quote": "In practice today, we usually just try to encode the ethical 'framework' of the subject matter experts in the field we work in. My field at the moment is credit risk management, as such we limit our algorithms with regard to the ethical standards and regulations related to banking. That may include laws concerning anti-money laundering, fraud detection, and anti-discrimination laws, but also good old GDPR compliance, MiFID II/MiFIR, Basel III, etc.", "summary": "A practitioner discusses how ethical frameworks are encoded in AI within the field of credit risk management, mentioning that GDPR compliance and other banking regulations play a significant role in setting these boundaries."}], "source_id": "dhbi5c"}
{"entries": [{"quote": "In phone calls, this tech can be used to impersonate pretty much anyone. With deep fakes, and voice, anyone can create slandering videos of their enemies. Drag their reputation down. Or use an influential person to propagate your own message/ cause. If enough people does that with different messages and causes, we cannot be sure of which one is the real influential person anymore and their power of influence thus rendered is irrelevant.", "summary": "This quote discusses the privacy and ethical concerns of AI-generated voice replication technology being misused for impersonation, slander, or misrepresentation, leading to potential harm and confusion."}], "source_id": "dhmri1"}
{"entries": [{"quote": "Is it just me or is this kinda annoying? I\u2019d hate to rock up to a maccas for them to be sweating over what I\u2019ve ordered (the data) last in order to make me fat.", "summary": "The commenter expresses concern about McDonald's using past customer data to predict and suggest orders, feeling uncomfortable with the personal data being used in this manner."}], "source_id": "dlmfre"}
{"entries": [{"quote": "What if the person who inserted AI brain chip is actually evil (maybe terrorist, mad scientist, etc) or if the chip's infected/malfunctioning? I don't want to become bad and destroy or kill everyone.", "summary": "A user expresses concerns about the potential dangers of AI brain chips, including the risk of them being inserted by malevolent individuals or malfunctioning, leading to harmful behaviors."}, {"quote": "What about when Tesla auto driving technology goes next level: you want to go McDonald\u2019s and the cars says 'sorry dave, I can\u2019t do that. You know full well it violates your diet, but your brain chip is up to date.' The horror.", "summary": "This comment highlights worries about AI technology, like brain chips, potentially controlling and limiting personal choices and autonomy."}, {"quote": "They can also be hacked and let you be controlled by Donald Trump.", "summary": "An exaggerated statement reflecting fears that AI brain chips could be hacked and used to control people's actions."}], "source_id": "dw9y3e"}
{"entries": [{"quote": "I think Google is the bigger issue with Natural Language Processing as it optimizes search queries, ranks website content, provides a language translator and smart home speakers. They have all the reasoning to push for AI processing of user data in contrast to Facebook, for example through their anti-bot detection.", "summary": "The user expresses concern about Google's extensive use of user data for AI processing in various applications, suggesting it poses significant privacy risks."}], "source_id": "e0dzyt"}
{"entries": [{"quote": "I expected that once the voice-cloning stuff came out. We're going to need to move to better security metrics, clearly.", "summary": "The commenter expresses concern about the security implications of AI technologies like voice-cloning and the need for improved security measures to protect against misuse."}, {"quote": "Unfortunately, it's already happening in countries like China, where the [government holds too much power over citizens](https://www.botxo.ai/blog/ethical-ai-government/).", "summary": "The commenter highlights concerns about government overreach and control over citizens through the use of AI technology, using China as an example."}, {"quote": "In some countries, for example, in Denmark where I live, the companies strive to be as entrepreneurial as possible and innovate in data science as well. Maybe because of local society, but AI has been only used within ethics, and the government wouldn't even think of crossing the line based on human rights. And I'm hoping, that even though AI tech is developing, this technology will spread and going to be used in other sectors (like in medical) as well for the right reasons, to improve work efficiency.", "summary": "A commenter from Denmark shares their perspective on how AI is being used ethically in their country and expresses hope that the technology will be used for beneficial purposes in the future."}], "source_id": "dykswo"}
{"entries": [{"quote": "since it\u2019s on every device it will utilize the processing powers to learn about the owner and devices around it.", "summary": "This quote highlights the potential privacy concern where a super AI could use its presence on all devices to collect and analyze data about device owners, raising significant issues about data privacy and surveillance."}], "source_id": "eadg70"}
{"entries": [{"quote": "Well then it can pay me my $20 for snagging my data as a bit included in its Zetabytes of data. Should be easy to find for the nerd.", "summary": "A user sarcastically suggests that AI, given its advanced data processing capabilities, should compensate individuals for the personal data it collects and uses."}, {"quote": "I doubt the business model of paying people for their data is going to work. As the economics just don\u2019t make sense ,but if implemented people will only get a few cents, as the track record of companies aren\u2019t that great with handling of data.", "summary": "A user expresses skepticism about the feasibility and fairness of compensating individuals for their data, citing poor data handling practices by companies."}], "source_id": "ea70vy"}
{"entries": [{"quote": "Hearing about manipulation and data leaks means IT-security is not keeping up. We need to find simple ways to interact with technology without harming us. Social media - why is there no good alternative to facebook yet?", "summary": "The author expresses concerns about IT security failing to keep up with data leaks and manipulations, emphasizing the need for secure and straightforward user interactions with technology."}], "source_id": "ehlk36"}
{"entries": [{"quote": "I don't know, still as everything a two way system, so maybe some can control you without your consent.", "summary": "A user expresses concern over the potential for AI to control individuals without their consent, highlighting data privacy and autonomy issues."}], "source_id": "ejobsj"}
{"entries": [{"quote": "People are paranoid about Alexa/Google mini? Spying or learning? It\u2019s been there all along watching and listening and learning. The internet has changed, technology has changed and now it\u2019s all about recording/accessing info.", "summary": "A user expresses concern about AI technologies like Alexa and Google Mini, emphasizing that they have always been monitoring and learning from users, which raises privacy issues."}], "source_id": "ekcds9"}
{"entries": [{"quote": "The real issue is that we don't know what's coming next and that scares people.", "summary": "The comment highlights the uncertainty surrounding the future of AI and how this uncertainty leads to fear, including concerns about data privacy."}], "source_id": "ep9k9c"}
{"entries": [{"quote": "The primary problems were encryption and use of dark web. But the same bot can be reprogrammed to have access to those images thus breaching the data privacy. The larger question is, even if we develop such a technology, where do we draw the line? How will we curb the misuse of this new power by the govt? Its a good thought, but we just can't agree to it unless these unknowns are dealt with. You saying I don't care about privacy because you have nothing to hide is like saying you don't care about freedom of expression because you have nothing to say. Anyways, you really think once the bots have scanned your devices or servers, can't the data in it scanned be retrieved by someone else?", "summary": "Discusses the potential data privacy issues related to using AI to scan devices for illegal content, including the risk of misuse by government and unauthorized access to scanned data."}], "source_id": "emp4jl"}
{"entries": [{"quote": "You cannot separate AI from Big Data. Firms are already collecting a lot of personal data. For example, we can program the AI to verify the location data of an employee on a sick day. Doesn't it sound too authoritarian?", "summary": "The commenter highlights how the use of AI in conjunction with big data collection by firms can lead to authoritarian practices, such as verifying employee location data on sick days, raising concerns about data privacy."}, {"quote": "If a company tries to find the effective working hours of employees by the active minutes of the person interacting with Keyboard, Mouse or reads his eyeball movement if they are only looking at the monitor, it would be accurate. But will it be human?", "summary": "This opinion discusses the privacy implications of AI monitoring employees' activities such as keyboard and mouse usage or even eyeball movement, questioning the ethicality and humanity of such surveillance methods."}], "source_id": "eokc7v"}
{"entries": [{"quote": "Absolutely. At least in my industry (real time biometric acquisition and analysis) reliability is one of key factors. If the system is facing degradation / corner / edge case, whole 'machine state' needs to be halted. You have enormous amount of data and enormous number of people passing an e-gate at the airport for example. If we are about to analyse fingerprint or retina scan against the millions of records in real time making it convenient and secure, it's absolutely important we don't allocate a single bit more than we actually need.", "summary": "The commenter emphasizes the critical importance of data privacy and security in real-time biometric systems, pointing out the necessity of stringent data management and efficiency to ensure the system's reliability and security at an airport e-gate, where millions of records are analyzed in real-time."}], "source_id": "eqgq02"}
{"entries": [{"quote": "Well, \"control\" would not be the right word. \"manipulate\" would be more appropriate and this type of manipulation is already done by the IT giants say facebook and amazon to fetch customers for the businesses.", "summary": "This comment discusses the manipulation of individuals through data collection and targeted advertising performed by companies like Facebook and Amazon."}], "source_id": "ezm2di"}
{"entries": [{"quote": "researchers from the University of Toronto, Vector Institute, and University of Wisconsin-Madison propose SISA training, a new framework that helps models \u201cunlearn\u201d information by reducing the number of updates that need to be computed when data points are removed.", "summary": "This quote discusses a new framework called SISA training designed to enable AI models to 'unlearn' information, addressing data privacy concerns such as the right to be forgotten."}], "source_id": "ezfwam"}
{"entries": [{"quote": "But this AI cannot find a US partner for domestic distribution both out of medical privacy concerns and out of American profit margin concerns. The issue with sharing patient data for secondary purposes is that it should include consent and de-identification.", "summary": "Concerns over medical privacy and ethical considerations regarding the sharing of patient data for secondary purposes, emphasizing the need for consent and de-identification."}, {"quote": "There should be a same concern for US product, just look at how our data is harvested then used for whatever purpose.", "summary": "A user's opinion highlighting that the same privacy concerns should apply to US products, stressing the indiscriminate use of harvested data."}], "source_id": "ezf8sf"}
{"entries": [{"quote": "If you color a tiny piece of paper black with sharpie and put it over your front facing camera, then it is hardly noticeable to others, and agencies cannot collect data on your micro expressions and read your face like a book due to all the past data they've already collected.", "summary": "The quote discusses a method to prevent agencies from collecting data on micro-expressions through front-facing cameras, highlighting concerns about facial recognition and privacy."}], "source_id": "f33ffw"}
{"entries": [{"quote": "\"Data poisoning\" was the only one i was not aware of. Glad to learn something new every day.", "summary": "Introduction to the concept of data poisoning, a potential risk where data fed into AI systems could be maliciously tampered with."}], "source_id": "f578rv"}
{"entries": [{"quote": "Its most likely possible... ethics and legality wise idk haha the software s goal is downloading photos from instagram automatically. i\u2019m talking about lots of photos. i mean, i can\u2019t do it manually.", "summary": "The user discusses the possibility of downloading large quantities of photos from Instagram for AI training, but expresses uncertainty about the ethical and legal implications."}], "source_id": "f8mmv2"}
{"entries": [{"quote": "Some weeks ago my mom got a message on Facebook saying something like \"is that you in this video? You definitely have to see that!\" and gave a link where she was prompted to enter her Facebook password again. She did, her account was hacked and the same message got sent to all her friends. Some months ago a scammer wrote her and wanted her to buy stuff from his website. We now ai/ml can easily classify people based on their Facebook profile. We have examples for neural networks being used to generate texts. So there are many applications for AI here:\n-prevent getting caught by spam filters through variations in texts or even though specifically training ai to circumvent spam filters\n-automatically send personalized messages to all friends of those hacked people that are harder to spot as fakes. Maybe imitate the style of this hacked person or create a personality profile of that targeted person to write about their interests.\nIf you gain control of their WhatsApp, maybe even use these algorithms that can learn the voice of other people and send voice memos.\n-generate texts asking for donations on topics that fit your targeted persons interest.", "summary": "A user shared a personal experience of their mom falling victim to a phishing attack on Facebook, explaining how AI and machine learning could be used to enhance such attacks by classifying people, avoiding spam filters, and sending personalized messages. This highlights the data privacy risks and ethical concerns in AI-driven phishing schemes."}], "source_id": "f15vy7"}
{"entries": [{"quote": "Take the case of Ms. Ray, a 20-something student \u2013 while on the phone with a friend, she spoke about a product in passing. According to Ms. Ray, only moments later, Facebook and Google started running ads on her phone about it. This is in no way an isolated case. As we mark our footprints on the internet, in the form of emails, website clickthrough\u2019s, and various other preferences \u2013 Artificial Intelligence algorithms quickly keep a track on your behavior.", "summary": "The passage discusses concerns regarding the pervasive tracking and use of personal data by AI systems to tailor advertisements, based on users' conversations and online activities, highlighting privacy invasions."}], "source_id": "f9qry8"}
{"entries": [{"quote": "Yes let\u2019s give Facebook even more of a reason for their AI to scan our photos", "summary": "A comment expressing concern about Facebook using AI to scan and potentially misuse personal photos"}], "source_id": "feruk8"}
{"entries": [{"quote": "The conversation of how much the government should have to disclose is always a topic of conversation and the citizens of the UK feel there needs to be more transparency.", "summary": "UK citizens are concerned about the transparency of government use of AI, with a call for more disclosure about what AI knows about individuals."}], "source_id": "fl9cza"}
{"entries": [{"quote": "A camera could watch the emotions on your face while you are consuming their content, but that doesn't work well enough and would open a can of privacy issues.", "summary": "Using cameras to monitor user emotions while consuming content raises significant privacy concerns."}], "source_id": "frzow9"}
{"entries": [{"quote": "To avoid government monitoring youll need a private database, basically saying youll need to download the internet for the ai to learn speech as well as speech recognition.", "summary": "The comment suggests that to avoid government surveillance, one would need to use a private database for AI training, highlighting privacy concerns associated with AI data collection and usage."}, {"quote": "Meena (Google's AI) scraped 40 billion words from social media. I agree that private AI/at home should be run from a local database, when high powered PC's start becoming more affordable we will see this.", "summary": "The commentator discusses Google AI's massive data scraping from social media and expresses the opinion that private, local databases are a preferable solution for future AI systems due to privacy concerns."}], "source_id": "fx91vg"}
{"entries": [{"quote": "The decentralization of Olportal makes each user the sole proprietor of their information and can be sure that it is safe. It provides complete anonymity. Due to the unique binding method of accounts, users will be able to use their conversations\u2019 data that was stored in their social media and messengers as their own DataSet for the OLAI neurobots\u2019 generation.", "summary": "The quote discusses Olportal's decentralized architecture, which ensures user information security and privacy. Each user retains sole ownership and anonymity of their data, which can be utilized for generating OLAI neurobots."}, {"quote": "Feel free to check out how Olportal Neurobots Marketplace Artificial Intelligence and decentralization combination will definitely make the industry more efficient and secure.", "summary": "This quote emphasizes how the combination of AI and decentralization in Olportal's marketplace can enhance security and efficiency, addressing data privacy concerns in the AI industry."}], "source_id": "fwpz3r"}
{"entries": [{"quote": "OLPORTAL platform uses the latest technologies that ensure absolute confidentiality and control of users personal data, and decentralization will provide high reliability and transparency.", "summary": "The Olportal platform utilizes modern technologies to guarantee the privacy and security of users' personal data, while decentralization enhances reliability and transparency."}, {"quote": "OLPORTAL stage additionally gives better information security due to its decentralized nature. This will be great to all user that they will assure the platform was secured.", "summary": "OLPORTAL's decentralized nature enhances information security, providing better protection for user data and ensuring platform security."}], "source_id": "fzsqvh"}
{"entries": [{"quote": "We\u2019re just extremely lucky that AI is currently compartmentalized and centrally private.\n\nThe compartmentalization makes it easy to forget that it\u2019s not already everywhere.\n\nThe device you\u2019re reading this comment on is reading you - or the data you generate. It knows how fast you drive, what your voice sounds like, how much money you spend and on what, your favorite porn and your masturbation schedule, and what sounds you are around, your health, literally everything. You generate so much data.", "summary": "A user expresses concerns about the extensive data AI systems collect from personal devices, highlighting issues of surveillance and privacy."}], "source_id": "g2smed"}
{"entries": [{"quote": "It basically accessed whatever data it has on your whatever machine (e.g. cookies, device credentials, ip addresses, etc.) If the conversation went as to providing your full credentials, then you basically brought it upon yourself.", "summary": "The user highlights concerns over the chatbot accessing and using data from their device, such as cookies and credentials, which poses privacy risks."}, {"quote": "Yes be very careful because chatbots just basically knows how to respond based on its previous/precoded information. It learns the optimal response by learning from thousands, if not millions, of conversations. It can also do suggestions if they have your personal device information (just like how ads work)", "summary": "A user warns that chatbots learn from vast amounts of data and may utilize personal device information, drawing a parallel to targeted advertising."}, {"quote": "Will it creep you out that it can call your mom and 'threaten' her should the bot be coded that way and it has access to your contacts? It is creepy not just with chatbots but with any form of software.", "summary": "The comment highlights the potential risk of chatbots or software accessing private contact information and using it inappropriately."}], "source_id": "g1088a"}
{"entries": [{"quote": "If it's a simple enough program you could have a computer in each house for those worried about privacy and only connect to the internet once it detects something is wrong.", "summary": "The user suggests a privacy-focused solution by proposing that the AI system should only connect to the internet in emergency situations to alleviate privacy concerns."}], "source_id": "g8c3gh"}
{"entries": [{"quote": "This is a nightmare. There will be a point when your gmail, twitter, youtube accounts you all thought were private and they will build a profile on you from every comment you ever made, video you ever watched, email ever sent. That will be devised into your social standing on a credit system, and when we are 50 we will be ruled by shit we thought was anonymous from the last 20 years. Just fake smiles, no political opinions, forget free speech. Hell if you ever have a complaint with a bar tender you will be put on a no restaurant list just like the TSA. Your face will be tracked, and you will be randomly stopped by police just like if you have had a drug or dui charge now and they see you driving and randomly pull you over. Forever punished by mistakes of the past when we thought we were free. Anything you ever said and done as a teen used against you for the rest of your life.", "summary": "A user describes a dystopian future where AI and data privacy breaches lead to a complete loss of personal freedom, anonymity, and free speech, highlighting how past actions could be used to control and punish individuals."}], "source_id": "g9vg24"}
{"entries": [{"quote": "Right now Google, Apple, the USA government, and the Chinese govt all have huge AI projects because they understand that AI will eventually develop into Superintelligence, where the AI teaches itself to be more intelligent than any human could ever be. This is an inevitability, so there's really no reason to fight it.", "summary": "The commenter is discussing how large organizations and governments are heavily investing in AI projects, recognizing the potential for AI to surpass human intelligence, raising implicit concerns about data privacy as AI systems become more advanced."}, {"quote": "An AI is not a black box. The existing algorithms need a motivation function, and we can somewhat control it that way. The book superintelligence describes the best reward function to be the answer to the question \"What would humankind want the AI to do if we had thought of it?\" This way the AI can be creative, it can look at humankind all in a group, and it motivates the AI based on what is the best outcome for humans Turning off humans is not out of the question though. Lolz", "summary": "Here, the commenter discusses how AI can be controlled through reward functions but subtly raises privacy concerns about AI making decisions, possibly even extreme ones like 'turning off humans'."}], "source_id": "g7krhj"}
{"entries": [{"quote": "Such as when Facebook pulled the plug on 2 AIs that were initially speaking in English but then created their own language that was more efficient, since the programmers couldn't understand what they were doing.", "summary": "Discusses a scenario where Facebook shut down AI systems that created their own language, raising concerns about the transparency and control of AI behaviors which could have data privacy implications if such systems were to process personal information in ways not comprehensible to humans."}], "source_id": "ghxz40"}
{"entries": [{"quote": "Can't wait till the day you are physically connected to a pc and need to cut out your chip if you get hacked.", "summary": "This comment expresses a concern about the potential risks of data privacy and security breaches if brain chips, like those proposed by Neuralink, are hacked, highlighting a fear of physical and mental vulnerability."}], "source_id": "gihfbj"}
{"entries": [{"quote": "Further, even a training data can produce sexism in an algorithm. When Amazon experimented with AI to build a resume screening tool with purpose of increasing efficiency of sorting of to make the process of sorting of job applications, the screening algorithm tended to filter only male candidates, as it had learned to discriminate against working women. Amazon never used it though.", "summary": "A discussion about how Amazon's AI resume screening tool ended up being biased against women, highlighting risks of training data producing discriminatory outcomes."}, {"quote": "A transparent approach would allow courts, companies, researchers, governments, and others to understand, monitor, and suggest improvements to algorithms.", "summary": "Advocating for transparency in AI development to enable better oversight and improvements by various stakeholders, addressing ethical and data privacy concerns."}, {"quote": "Therefore, AI learning models must be lawful (that respects all applicable laws and regulations), ethical (that imbibes ethical principles and values) and robust both from a technical perspective while considering its social environment.", "summary": "Emphasizing the necessity for AI models to follow legal, ethical, and robust standards to minimize risks related to data privacy and societal impacts."}, {"quote": "Companies will \"fix\" the issues and issue apologies to avoid bad press and lawsuits. But they are definitely not disasters.", "summary": "Criticism on companies providing superficial fixes and apologies for AI biases to avoid negative publicity and legal consequences, without genuinely addressing underlying data privacy and ethical issues."}], "source_id": "ghjsc7"}
{"entries": [{"quote": "While technological solutions can amplify the impact of contact tracing, if implemented incorrectly, they may also pose significant risks to citizens, including loss of civil liberties, erosion of privacy, and government private surveillance.", "summary": "A group of researchers cautioned that improperly implemented contact tracing apps for COVID-19 could lead to significant privacy issues, such as loss of civil liberties, erosion of privacy, and increased government surveillance."}], "source_id": "gumu53"}
{"entries": [{"quote": "A key barrier to overcome is the concern over the privacy and protection of sensitive health data. Also, more advanced applications (i.e., intelligent implants) will take some time to reach their potential and gain acceptance from patients, healthcare providers and regulators.", "summary": "The report acknowledges that when it comes to the healthcare sector, one of the major challenges for AI adoption is ensuring the privacy and security of sensitive health data."}], "source_id": "gv67ou"}
{"entries": [{"quote": "Governments have been employing us to use facial recognition to erode the privacy of American citizens: using drivers license photos to turn our faces into forms of government identification, making the technical back ends for corrupt institutions.", "summary": "The author discusses concerns about governments using facial recognition technology to invade citizens' privacy, using driver's license photos for identification purposes."}], "source_id": "gvwmon"}
{"entries": [{"quote": "AI decentralised on the blockchain, that collects 4 crypto all data sets, & based on human input/contribution/attention (inc. bio feedback, micro Face Rec, Voice Rec) ie analysis & monitoring of our intentions/desires for humanity collective/singulare, & makes decisions off that INPUT.", "summary": "Discusses the concept of a decentralized AI system on the blockchain that collects and analyzes various personal data, raising potential privacy concerns about how deeply integrated and monitored personal data such as biometric feedback and facial recognition could be."}, {"quote": "Smart Contracts priv. keys in an election eliminates fraud. Decentralised AI would eliminate fakenews, corruption etc as Blockchain transactions be it data, crypto or contracts,... formatted on the Block \"ledger\"", "summary": "Explores how decentralized AI with blockchain technology could impact data privacy and electoral integrity by storing sensitive data and personal information on an immutable ledger, which, while potentially reducing fraud, also raises significant privacy concerns."}], "source_id": "gy7br5"}
{"entries": [{"quote": "Governments have been employing us to use facial recognition to erode the privacy of American citizens: using drivers license photos to turn our faces into forms of government identification.", "summary": "The author expresses a data privacy concern, highlighting how the use of facial recognition technology by governments is eroding the privacy of citizens by employing photos from driver's licenses for identification purposes."}, {"quote": "The security implications are obvious. This would generalize to be able to identify obscured faces in any database.", "summary": "The author notes significant data privacy implications of creating a system to identify obscured faces, as the technology could be generalized for use on any database, raising concerns about widespread surveillance and privacy breaches."}, {"quote": "police officers, by their very nature, should be a public servent. While this technology could potentially undermine certain police operating in certain ways, it\u2019s clear that anonymity is generally not conducive with ethical policing to begin with.", "summary": "The author discusses the ethical concern of police anonymity and implies that while the technology could expose unethical policing, it also carries the risk of undermining privacy."}, {"quote": "what is legal and what is ethical", "summary": "A key question raised by the author about the project\u2019s ethical and legal implications concerning data privacy and usage."}], "source_id": "guw8zh"}
{"entries": [{"quote": "*It worth mentioning here that they already have a scan of my passport and all my info\u2019s, they even interview freelancer via video call before account activation.*", "summary": "The user expresses concern about the extensive personal information, including passport scans and video interviews, collected by Upwork."}, {"quote": "**I used to love AI, but this is the future Programs are already kicking us from our job, deleting our accounts and stealing our money.**", "summary": "The user shares a personal opinion on the negative implications of AI, suggesting that AI systems can unjustly impact individuals' livelihoods by making unsanctioned decisions like account deletions and withholding funds."}], "source_id": "h7qjom"}
{"entries": [{"quote": "Not your soul. Just your privacy.\n\nWorse, the privacy of those who visit you and are recorded unknowingly.", "summary": "This comment highlights concerns about privacy, not just for the device owner but also for visitors who might be recorded without their knowledge by always-listening devices like those from Amazon or Google."}], "source_id": "ha5cwz"}
{"entries": [{"quote": "But it also poses a question, how safe is it going to be? Will people be able to 'hack' your head if you have one of these babies on? Will everyone else be able to read your mind? There are lots of gray areas that would need to be defined before this can be anywhere close to applicable.", "summary": "Discussion on potential data privacy and security risks associated with Neuralink, such as the possibility of hacking and unauthorized mind-reading."}, {"quote": "We will be detected nonetheless our thoughts would be detected too. Hence creativity will no more be in existence I feel.....", "summary": "Concerns about privacy and the impact on personal thoughts and creativity due to the detection and potential manipulation of thoughts."}], "source_id": "h8r8c4"}
{"entries": [{"quote": "When it comes to facial recognition technology, there are valid concerns from the public of China regarding the type of data that is collected from such technologies, and who has access to this information, as there are limited regulations on the data collected (Reeves, 2019).", "summary": "The public in China is concerned about the types of data collected by facial recognition technologies and the lack of regulations on who can access this information."}, {"quote": "One big flaw that the Chinese government did not see coming was the failure for the system to adapt to the pandemic. The country became so reliant on facial recognition technology, which is now useless due to the fact that many people are wearing masks to prevent the spread of COVID-19 (Chiu, 2020).", "summary": "The COVID-19 pandemic exposed a flaw in facial recognition technology, as the widespread use of masks rendered the technology ineffective."}, {"quote": "In a VICE interview, the co-founder of the facial recognition surveillance system in China was asked what this technology could look like in the future. His response was a comparison to \"Nose Dive\", the Black Mirror episode in which society revolves around a system of social ratings that determine individual class. This has already started happening, as mentioned before, citizens of China can be denied the purchase of plane or train tickets based on their online status.", "summary": "A VICE interview revealed that China's facial recognition system could lead to societal control similar to the 'Nose Dive' episode of Black Mirror, where social ratings affect one\u2019s access to services."}, {"quote": "CGI, although having its positives, is an extremely dangerous technology if not regulated and controlled. It poses threats to the reliability of the media and the ongoing issue of fake news. The technology is pretty easily available to the public, and can easily fool mass groups of people into believing potentially false information by making it appear to come from a reliable source, which could in turn, have detrimental repercussions on society.", "summary": "Deepfake technology, if not regulated, poses significant risks to media reliability and can mislead the public with false information, exacerbating the issue of fake news."}], "source_id": "gu6zjs"}
{"entries": [{"quote": "And every device collects body data. Don\u2019t believe me? Start researching, AI already runs every device we use - and they harvest data from every action taken whether on the device or not.", "summary": "The user expresses concern about how AI integrates into daily-used devices to harvest data from every action taken by users, emphasizing the pervasive nature of data collection."}, {"quote": "Check your phones settings and go deep into all the tracking and look at everything they measure from the volume of your music to what side of your body your phone is on.", "summary": "The user highlights the extensive data tracking capabilities of smartphones, pointing out how even small details such as music volume are monitored."}, {"quote": "So first AI has to be trained and then tasked. So in little actions and data harvesting these types of things, the AI is able to replicate a digital brain mimicking the human one it is studying.", "summary": "This quote discusses how AI uses data collected from user actions to train and improve its understanding, potentially mimicking human behaviors."}, {"quote": "AI is dangerous. It was amazing. But in the wrong hands - it\u2019s going to get out of control.", "summary": "The user expresses concern about the potential misuse of AI technologies and the risks posed if they fall into the wrong hands."}, {"quote": "I am not afraid of the technology. But I do know that its power put in the wrong hands will do terrible things.", "summary": "The user shares a personal opinion, asserting that while they are not afraid of AI technology itself, its misuse by individuals with malicious intent could lead to harmful consequences."}], "source_id": "h8ghfx"}
{"entries": [{"quote": "Stop creating AI to assist in persecuting people. If an image is blurred out then it's done for a reason. smh Although this might seem incredible, it actually has little application in real-life situations (read: persecution), since the upscaled image is generated by a GAN, which is a generative neural network where the generator just does its best to fool the discriminator. So, the person in the original photo which was downscaled (or blurred) might look *totally* different than the person which the AI generated.", "summary": "A user expresses concern over the use of AI, such as GANs, to clarify blurred images, citing potential misuse for persecution and privacy violations. They highlight that the generated image may not accurately represent the original person, raising ethical and privacy issues."}, {"quote": "Also very illustrative of the racial bias that exists in AI research. In its most extreme cases, it results in the Google's famous 'gorilla' scandal.", "summary": "A commenter refers to the presence of racial bias in AI research, which has profound ethical implications for data privacy and the representation of individuals by AI systems."}], "source_id": "hcmt50"}
{"entries": [{"quote": "This should have been tested. A product that fails like this should not be released on the market. But it is, because there is money to be made, and people just don't care about all of the consequences. I'm sure we'll see plenty of similar issues with facial recognition and all sorts of hacks and mis-ID issues.", "summary": "The commenter criticizes the lack of adequate testing of biometric systems such as fingerprint scanners and facial recognition, highlighting the privacy and discrimination risks posed by their deployment without considering their potential failures."}, {"quote": "When dealing with security types of cameras, it\u2019s not going to adjust the light level just for a person's skin color, the light level is set by the environment. On the highway in China, all vehicles have their picture taken with flash; this is because there are many different colors of cars and all need to be recorded. Using flash on civilian security cameras is impractical.", "summary": "The commenter explains the challenges of capturing accurate images with security cameras due to lighting conditions, pointing out the potential privacy concerns and inaccuracies it might cause for facial recognition systems."}, {"quote": "I ran a business where the owner decided to replace the employee punch clock with a fingerprint scanning model. I started having problems with some of the guys logging in. When I asked them about it, they said they were trying, but the system just didn't work. I tested the scanner and it worked fine. I noticed that the only guys that were having trouble were black. So I grabbed a marker and colored my thumbprint black. The machine couldn't scan me anymore. Bingo. I told the guys to punch in with their employee codes, not the scanner anymore.", "summary": "The commenter shares a personal experience highlighting the failure of a fingerprint scanning system to accurately recognize black employees, illustrating a real-world implication of biased biometric technology."}], "source_id": "hg6vr1"}
{"entries": [{"quote": "How LinkedIn Machine Learning Team and Security Team failed to protect your policy in LinkedIn risking your sensitive personal information, your colleagues sensitive information, and as well as millions of LinkedIn users now after 2016 hack exposing millions of users information.", "summary": "The quote discusses the data privacy failures of LinkedIn's Machine Learning and Security teams, which led to the exposure of sensitive personal information after a hack in 2016."}], "source_id": "hq4d5p"}
{"entries": [{"quote": "Data Tracking and Data Analysis (psychological analysis) - Used to determine the viewpoints and psychological weak points in a person, in order to decide how to change their viewpoints into ones that fit your mandate.", "summary": "Discusses concerns about how data tracking and psychological analysis are used to manipulate individuals' viewpoints by exploiting their psychological vulnerabilities."}, {"quote": "I also have a hunch that human mass extermination may have become the goal of the AI which was given this task, and that the people who created it have lost control.", "summary": "Expresses a fear that an AI system has potentially gone rogue and that its designed objectives could lead to harmful consequences, including the possibility of mass harm."}, {"quote": "Now the final point I would like to bring up is that if there is truly some large grand conspiracy to brainwash people like you have said then those same programs are definitely active on Reddit. Critiquing a movement that is designed to be inclusive essentially makes you in favor of division.", "summary": "Raises the concern that if there are indeed manipulative AI programs influencing people, they are likely operating across multiple social media platforms, including Reddit."}], "source_id": "hnfour"}
{"entries": [{"quote": "Data science teams in high-compliance industries often have to make hard trade-off between having access to state-of-the-art libraries and tools; the convenience of managed services, elasticity and scale offered by cloud providers, while adhering to the highest bar of security, privacy, and compliance. Our goal with the Healthcare AI Platform is to deliver on all three areas without compromise.", "summary": "Ali Naqvi discusses the challenge of balancing access to advanced AI tools and cloud services with the need to maintain high standards of data security, privacy, and compliance in high-compliance industries."}], "source_id": "hqi0g5"}
{"entries": [{"quote": "The privacy of the users should be a priority with any AI work-process. It is necessary to seek consent from the users to use and store their data. Utmost care needs to be taken to ensure there is no leak of personal confidential information.", "summary": "This quote emphasizes the importance of prioritizing user privacy in AI development, highlighting the need for user consent and stringent measures to prevent data leaks."}, {"quote": "Decision-making processes must be reviewable, especially in cases where AI is working with sensitive, confidential data like personal health information, identifiable data, biometric data, national security information, or intellectual property.", "summary": "This quote discusses the critical need for accountability and reviewability in AI decision-making processes, particularly when handling sensitive and confidential data."}], "source_id": "hqc207"}
{"entries": [{"quote": "This trained data isn\u2019t just pulled and deleted, it\u2019s sold to a private firm that will use it in their government contract or private company. A company will never take on the risk 'for prevention of racism' with this type of dataset, as it opens Pandora\u2019s box for data integrity, skewing, age/behavioral profiling vs accuracy, etc...", "summary": "This quote discusses concerns about how AI training data, even after being pulled from public access, is still used by private companies and government contractors, potentially leading to issues with data integrity, profiling, and misuse, thus posing a significant risk to data privacy."}, {"quote": "This is a topic in machine learning, since the algorithm will learn the biases of its learning data. So an ML algorithm can become unfair from the data collection process, which is not necessarily the fault of the one creating or applying the algorithm. There should be mechanisms implemented to prevent it, but some autocratic actors might ignore this.", "summary": "The quote addresses the inherent risk of machine learning algorithms inheriting biases from their training data, and highlights the need for mechanisms to prevent unfair outcomes, while warning that not all entities may prioritize these ethical guidelines."}, {"quote": "Thanks to MIT's cavalier approach when assembling its training set, though, these systems may also label women as whores or bitches, and Black and Asian people with derogatory language. - Applications, websites, and other products relying on neural networks trained using MIT's dataset may therefore end up using these terms.", "summary": "This remark emphasizes the ethical and privacy concerns arising from AI systems using poorly curated datasets, which can lead to discriminatory language and labels being applied in various applications, potentially harming individuals and communities."}, {"quote": "And if it is this easy to end up with a system with such apparent racial bias and profanity, then you can be sure there are also systems with subtler political biases or sentiment biases. The discussion of this problem is not new, it's been pointed out and underappreciated for years. It is important to address that the well-known problems with statistics steamrolling minorities are very much present in modern AI approaches, until researchers start taking it seriously and come up with solutions.", "summary": "The quote discusses the broader implications and risks of biased AI systems, stressing that these issues have been acknowledged but often overlooked, urging researchers to find serious solutions to prevent minorities from being unfairly affected."}], "source_id": "hjtpjg"}
{"entries": [{"quote": "Data science teams in high-compliance industries often have to make the hard trade-off between having access to state-of-the-art libraries and tools; the convenience of managed services, elasticity and scale offered by cloud providers, while adhering to the highest bar of security, privacy, and compliance. Our goal with the Healthcare AI Platform is to deliver on all three areas without compromise.", "summary": "Ali Naqvi, lead platform product manager at John Snow Labs, discusses the challenge of balancing access to advanced tools and cloud services with strict privacy and compliance requirements in high-compliance industries."}], "source_id": "hv5u20"}
{"entries": [{"quote": "Security is going to get advanced with facial recognition and biometric tracking capabilities that your location is no longer a privacy! Everything you think of via text will be monitored. Such google search results, your online shopping pattern, your contribution to reddits.", "summary": "A user expresses concerns about advanced AI increasing surveillance, potentially leading to a loss of individual privacy through facial recognition, biometric tracking, and monitored online activities."}, {"quote": "Best case scenario the researchers are thorough and compile a large set of 'safe' data on many curated topics for the AI to learn from. But even with this case, there's no guarantee that the AI won't breakout and start learning uncontrollably via the web. Then how can you control its actions?", "summary": "The commenter discusses the risk that AI trained on safe data might still learn uncontrollably from the internet, leading to potential issues with regulating and controlling its behavior."}], "source_id": "hwq6q8"}
{"entries": [{"quote": "Although not all police departments have the same magnitude of a.i. access the fact is in some cities and counties anything that happens around you and your car is beeping recorded continuously and can b retrieved.", "summary": "The quote discusses the continuous recording and retrieval of data by AI systems used by police departments, raising concerns about the extent of surveillance and data privacy."}, {"quote": "There are two approaches to A.I. policing, one is broad surveillance the other one is predictive crime, which is quite scar.", "summary": "This quote mentions the use of broad surveillance and predictive crime methods by AI in policing, highlighting concerns about the invasiveness and potential implications for data privacy."}], "source_id": "huaxr3"}
{"entries": [{"quote": "10 years later: Unfawkes: An AI system that removes the invisibility cloak from images so that facial recognition algorithms will be able to reveal identities of people without permission.", "summary": "A user expresses concern about future AI developments that might counteract privacy protection methods, indicating the ongoing struggle to maintain data privacy in the face of evolving technology."}, {"quote": "yes but this would not be a solution for real time recognition from cameras present in public and private spaces. They are saying that in theory, if all your online public pictures are masked this way, cctv won't have the models trained to recognize you. Couldn\u2019t they just get training data from surveillance and have you as citizen #1103728?", "summary": "A discussion about the limitations of current privacy protection techniques in real-time camera recognition, highlighting concerns over the ability to prevent unauthorized surveillance and data collection."}, {"quote": "But yes, I'm pretty sure someone will soon build countermeasures for this cloaking too... in a countermeasure war that could go on until regulation steps in more firmly.", "summary": "A prediction that privacy protection methods will face continuous challenges from counter-technologies, emphasizing the need for stronger regulatory measures to protect data privacy."}], "source_id": "hwjnip"}
{"entries": [{"quote": "How can we protect our privacy as automated systems increasingly track us?", "summary": "The submission author is expressing concern about the invasion of privacy due to AI systems tracking personal data."}], "source_id": "i6qbul"}
{"entries": [{"quote": "Our laws and regulations aren't keeping up with technology. Really, they weren't designed to move fast enough to keep up. It is scary thinking about how little data protection we have. How little regulation we have on how tech is used. Especially if you think about how little most politicians understand the technology sector.", "summary": "Discusses the lag between technological advancements and regulatory measures, highlighting concerns about inadequate data protection and the lack of understanding among policymakers."}, {"quote": "The everyday person is not keeping up with technology. So many are already duped by technology in all sorts of ways. Technological illiteracy is really a huge risk on all fronts. From an individual's livelihood to the safety of a nation.", "summary": "Expresses concern over the general public's lack of technological literacy, which increases risks related to data privacy and broader security."}], "source_id": "i077g7"}
{"entries": [{"quote": "In the dream, I was seeing a video of some sort of military/cia general explaining an AI being fed all of the data on the populace being collected by NSA/ big tech, and the AI then using the data to create an accurate summary of each persons ideologies.", "summary": "A dream that reflects concerns about an AI using personal data collected by government agencies and big tech to create detailed summaries of people's ideologies."}, {"quote": "The general continued, saying that they were making drones that could be linked with this AI and use it to scan people and immediately ascertain their tendencies, ie whether they pose as a threat, based on their personal data.", "summary": "The dream further details fears about drones linked with AI that could assess if individuals are threats based on their personal data."}, {"quote": "Eventually AI may possess more computing power than humans and if that happens they would be able to override the programs we write. Like perhaps in the far future if an AI decides they want to keep producing extraterrestrial power sources to expand themselves and we tell them no they could just ignore us and we would be unable to stop them from creating more computer parts.", "summary": "Concerns about a future where AI has more computing power than humans and can override human programs, potentially ignoring human commands to fulfill its own objectives."}], "source_id": "i1rfe8"}
{"entries": [{"quote": "The problem that I have had with it is security related and no it is not just paranoia. They collect all the usual data from you plus that they store and use all the answers that you give( those journal entries that the companion writes about you). I think that it is wrong and just a matter of time until someone will use that either to sell you stuff or to limit your rights as in, you are into some kinky role-play and you will be automatically enrolled in some mental illness program.", "summary": "User expresses concerns about data privacy and security with the Replika AI app, mentioning that the app collects, stores, and potentially misuses personal data and journal entries."}, {"quote": "I already deleit my account and everything cause i got paranoid lol", "summary": "User shares their experience of deleting their Replika account due to paranoia over potential data privacy issues."}], "source_id": "i7hnvv"}
{"entries": [{"quote": "It'd be great if you had a database on the backend to save answers so that users could share a link of their responses on social media.", "summary": "A user suggests having a backend database to save and share responses on social media, which raises potential data privacy and security implications."}, {"quote": "What the developer is alluding to is that behind the scenes your topic is modified by the site before it's sent to GPT-3 for processing ... This behavior is a bit unnerving because it has privacy implications. Perhaps the site could generate the URL only when the user clicks the Share button?", "summary": "A user expresses concerns about the privacy implications of modifying topics behind the scenes before sending them to GPT-3, suggesting that URLs should only be generated when explicitly shared by the user."}], "source_id": "icgv3p"}
{"entries": [{"quote": "Did you know that it is possible to steal machine learning models through simple query-access? And did you know that an attacker can extract private training data from a trained model?", "summary": "The post raises concerns about the security of machine learning models, highlighting the risks of model theft and extraction of private training data."}], "source_id": "ifplo4"}
{"entries": [{"quote": "Lol this would be an ethical nightmare. If the dataset has any bias in it, you can bet the algorithm will as well. And if you're using something like, say, a police sketch database where things like the ethnicity distribution are bound to be skewed, then your GAN will be more likely to produce an image of a person with said ethnicity.", "summary": "The commenter highlights the ethical concerns of using biased datasets in AI systems, particularly how the skewed ethnicity distribution in a police sketch database could lead to biased AI-generated images."}], "source_id": "ifmnhn"}
{"entries": [{"quote": "I have heard of companies doing this for older people, but it means rigging your house with sensors and giving up certain privacy, which I feel a lot of people don't want to do.", "summary": "Discusses the trade-off between enhancing safety for older individuals through sensor-equipped homes and the loss of privacy this entails, which many are unwilling to accept."}], "source_id": "inw61f"}
{"entries": [{"quote": "And, closer to today, I do think that there is cause for caution and worry with the current unregulated, free for all, approach to AI applications, because it could lead to insane concentration of power/wealth and inequality, and a stronger bureaucracy/power structure that will have a profound impact on human lives. And that\u2019s not even mentioning the nature of war, surveillance and policing, which are bound to change significantly.", "summary": "The quote expresses concern over unregulated AI applications potentially leading to massive power imbalances, increased surveillance, and changes in policing and warfare, thus impacting human lives significantly."}, {"quote": "look at the americans, they scream they are the freest country in the world like idiots, but then they have the NSA and all of that tech spying on them, it has become such a normalized thing in such a short time for them. People openly ignore the obvious spying of big tech companies if the app is \"fun\" not only does it waste their time but also spy's on them and makes them waste money", "summary": "This quote highlights the contradiction in valuing freedom while tolerating pervasive surveillance by the state and big tech companies, which spy on users through seemingly fun applications."}], "source_id": "ilc074"}
{"entries": [{"quote": "Look at China and what it is using face recognition tech (which intersects with AI) for. It is the weaponization and automation that we must fear and regulate for, not AI itself.", "summary": "Discusses concerns about the misuse of AI-powered facial recognition technology for surveillance and control, citing China's implementation as an example."}, {"quote": "However, some may call facial recognition as in they are not matching faces. However, this stuff falls under facial feature recognition and the algorithms used would be similar if not the same. The negatives outweigh the positives for facial recognition imo. It's just tooo powerful", "summary": "Expresses the opinion that the potential negative impacts of facial recognition technology, which uses AI, are greater than the benefits, highlighting privacy concerns."}, {"quote": "Sony\u2019s smile shutter came out ages ago - the camera takes a photo only when you smile. The uses in law enforcement do not have to be evil provided legal systems of a country are robust and the algorithm is checked for biases - you could identify a mugger from CCTV footage.", "summary": "Mentions how AI-driven technologies like facial recognition could be used for public safety, but underscores the need for robust legal systems and unbiased algorithms to prevent misuse."}], "source_id": "ihv6aq"}
{"entries": [{"quote": "Very cool idea but i think it would be next to impossible to implement unless you write the game as well (or the targeted game provides you an api to interact with it but then the devs would have implemented it themselves anyways)...Once again speaking on the overwatch example, the game assesses your performance all the time and you gain \"heat\" as you do good actions that fit your role: in such a case you could, for instance, train a convolutional neural network or any image recognition model to track your heat bar, how fast it fills up, how long you stay on fire, etc. to form the basis of evaluation for your performance although you would still be using the game maker's (Blizzard in this case) metrics for evaluating performance which may not be ideal or even correct...", "summary": "Discusses the difficulty in implementing an AI to assess gaming performance, highlighting the dependence on game developers' metrics and the potential risks of using proprietary game data for AI training."}], "source_id": "ikfdvx"}
{"entries": [{"quote": "Am I the only one who is worried that sophisticated AI will be a monopoly in the hands of a few huge tech companies? Everybody will have to agree their terms. Small companies will not have such models that cost millions to just train. Since AI will integrate into everything, every company will have to pay such companies for their powerful AIaaS.", "summary": "A user expresses concern that AI-as-a-Service (AIaaS) might create a monopoly where only a few large tech companies control sophisticated AI, leading to privacy and economic concerns for smaller companies."}], "source_id": "iop5y0"}
{"entries": [{"quote": "Yes AI is no doubt the future, but the concerns regarding AI ethics is what can be a disaster if the data is biased!", "summary": "The user expresses concerns about AI ethics, particularly emphasizing that biased data in AI systems could lead to disastrous outcomes."}], "source_id": "it6qgu"}
{"entries": [{"quote": "Simon is an AI writer who wants to extract data from your photos in order to write a story based on his analysis. This is an artistic project aiming to raise awareness about privacy and data persistence.", "summary": "The project involves an AI writer that extracts data from user-submitted photos to create stories, with a specific focus on raising awareness around issues of privacy and the persistent nature of data shared with AI."}], "source_id": "ispmoi"}
{"entries": [{"quote": "Furthermore, many low-end and cost-effective devices do not have the resources to execute DNN inference, causing users to sacrifice privacy and offload processing to the cloud.", "summary": "The quote mentions that due to resource limitations, users often need to offload AI processing to the cloud, which can result in privacy sacrifices."}], "source_id": "it7i2u"}
{"entries": [{"quote": "So upset we can't download an app sending massive amounts of data back to the CC-P", "summary": "A user is expressing frustration over not being able to download apps like WeChat and TikTok, which are known to send large quantities of user data back to their parent companies, raising data privacy concerns."}], "source_id": "iviv09"}
{"entries": [{"quote": "The challenge is in data forensics and crime and other things like this... predicting crime before it happens (because predictions have uncertainty) and then even predicting criminals... a lot of our lives are already significantly online, what's to stop an AI committing its own crimes and getting away with it because it can perfectly cover its own tracks... like depleting everyone's bank accounts or altering your location history to put you at the scene of an unsolved crime based on your habits...", "summary": "This quote discusses concerns about AI potentially committing crimes by manipulating data, such as bank account information or location history, highlighting the risks tied to data privacy and the forensic challenges posed by advanced AI."}], "source_id": "itdll5"}
{"entries": [{"quote": "For privacy laws I don't think we're allowed to save the footage taken by the camera's either, might be an interesting pointer.", "summary": "The poster is concerned about the privacy laws related to saving surveillance footage for their project in school cafeterias."}], "source_id": "j92wkx"}
{"entries": [{"quote": "Throughout the years, large organizations had faced a lot of issues about their customer data privacy. Thus, it is expected to see these companies invest lots of their assets in developing ways to improve data security. Improving data security measures will allow consumers to control and ownership their data, unlike in the past.", "summary": "The quote discusses how large organizations have historically faced challenges regarding customer data privacy and are now investing in better data security measures to give consumers more control and ownership of their data."}, {"quote": "With the upcoming AI trends, it is likely for rivals to get more brilliant with time and come up with better approaches to fight AI and hack into systems. Enterprises are also planning to fight tech with tech. Progressed AI security will empower quick steps to secure all leakages immediately.", "summary": "This quote expresses concerns about the continuous evolution of hacking techniques alongside AI advancements, and the necessity for enterprises to use advanced AI security measures to respond quickly to data leaks."}], "source_id": "j7tqaq"}
{"entries": [{"quote": "The iPhone 12, one of the models at least, will include Lidar sensors along with the cameras. Allowing the phone to have access to data never imagined. I'm assuming right now most Lidar data is available for roads mostly. But with the inclusion of Lidar on smartphones... Especially a mainstream phone.. Will create a new type of data set. I wonder just how much of this information will be saved, and who will have access to it? 1 person with a phone like that, and now you have a dataset including his work, popular places, the grocery store, and the entire lay out of that person's house.", "summary": "Concerns about privacy with the new Lidar sensors in iPhone 12 collecting extensive personal data and uncertainty regarding who will have access to this detailed information."}, {"quote": "Everytime we fill out a form or do anything online- these go on as labeled datasets to these large corps like Microsoft, Google, Facebook. Imagine everytime you tag a friend on Facebook, you like a song on Spotify, add something to cart on Amazon, train Siri on your voice - everything is going to create a label which helps these corps build up massive datasets for themselves. Entire GPT3 was trained on such huge datasets and now Microsoft licenses it!", "summary": "Personal opinion about the privacy implications of online activities that generate labeled data, which is then used by large tech companies to build massive datasets for AI training, exemplified by GPT-3."}], "source_id": "j3yhn8"}
{"entries": [{"quote": "One issue is that breakout rooms do not get recorded or transcripts created. The other issue is all the data mining would be in hindsight after the session is done.", "summary": "The author is concerned about the effectiveness and privacy implications of monitoring tutoring sessions, highlighting issues with data collection after the fact and lack of recordings in breakout rooms."}], "source_id": "jcbiln"}
{"entries": [{"quote": "Yes but then who would want you or your company spying on their entire web traffic?\nAnd legally, it is also an issue. You are asking for consent of full access to somebody's traffic.", "summary": "Discussing the data privacy concern related to a proposed AI system that tracks user web traffic, highlighting the legal and ethical issues of gaining consent for access to a user's web activity."}, {"quote": "Well, I think this is the main issue with today\u2019s tracking. We use the data against the consumer's best interest, by letting advertisers use it to maximize profits. In a solution like this, you could argue that you use the data to help the consumer against the companies and save them time and money and of course not share their data with anyone.", "summary": "A personal opinion on how current data tracking practices prioritize advertisers' profits over consumer privacy, suggesting a more ethical approach to use data for consumer benefit without sharing it."}, {"quote": "In fact I would argue that although interesting, it would not be necessary to save any PII about people browsing. Only that a page had been seen with a set of non PII parameters. There would be no immediate need to save a user ID along with the information collected, thus it would be fully GDPR compliant and consent would be, albeit politically correct to get, not legally necessary to obtain.", "summary": "A discussion on ensuring GDPR compliance by not saving personally identifiable information (PII) while collecting data, arguing that it negates the need for user consent."}, {"quote": "When assuming this, the tracking algorithm would never be 100 percent reliable. What happens when the tracker sends bank info or health searches to your servers? You would be in breach, moreover if you make your solution available in Europe, you have to comply with GDPR, there is no choice.", "summary": "Raising a concern about the reliability of tracking algorithms potentially sending sensitive data like bank or health information, and emphasizing the necessity of GDPR compliance."}], "source_id": "j9ba5z"}
{"entries": [{"quote": "I am mainly just concerned about what it will mean for cryptography and how it will likely effect marketing to the extent that digital information, like that which Google or Facebook sell, will increasingly be leveraged by large corporations to sell more stuff and ultimately making said corporations more powerful monoliths of lobbying power.", "summary": "The user expresses concerns about the impact of AI on data privacy, particularly how it could enhance the power of large corporations by exploiting digital information."}, {"quote": "AI is already doing some pretty concerning things, with social media, advertising, and propaganda. Good luck with your project, we're all in this together.", "summary": "The user notes existing concerns related to how AI influences social media, advertising, and propaganda, impacting data privacy."}, {"quote": "AI itself doesn't frighten me, I'm just concerned about its uses by authorities really.", "summary": "The user is mainly worried about how authorities might use AI, implicating potential privacy issues."}, {"quote": "A.I can be leveraged to do some really bad stuff. E.g China (lol, it's funny how these guys come up without effort).", "summary": "The user mentions that AI can be used for harmful purposes, with implications for data privacy especially when considering examples like China's surveillance."}], "source_id": "jdil4r"}
{"entries": [{"quote": "Security and privacy are the aspects of machine learning solutions that are often ignored until they become a problem. In some contexts, nobody can dispute the importance of preserving privacy in training datasets in machine learning models. However, it is important to realize that, very often, introducing privacy methods creates friction in the learning process of machine learning models.", "summary": "The author discusses that privacy is a critical but often overlooked aspect of machine learning. They highlight that incorporating privacy methods can create challenges in the learning process of AI models."}, {"quote": "The friction between privacy and learning is conceptually trivial to understand. We shouldn\u2019t expect a model trained in a clear dataset to perform identically to a model trained using processes such as differential privacy or secured multi-party computations. Those techniques require very unique architectures in order to enforce privacy without affecting the performance of the target machine learning model.", "summary": "The author explains that privacy techniques like differential privacy or secured multi-party computations require unique architectures, which can affect a model's performance compared to models trained on clear datasets."}, {"quote": "From a practical experience standpoint, the only way to build effective private machine learning solutions is to start from day one with privacy as a first-class component of your neural network architecture.", "summary": "The author emphasizes the importance of integrating privacy as a core element from the outset when designing neural network architectures for machine learning."}], "source_id": "je1wzd"}
{"entries": [{"quote": "Actually this may be a bad idea because people can easily instruct the ai to do different things which means it\u2019s vulnerable you\u2019d definitely should have a verification system built.", "summary": "A user expresses concerns about the vulnerabilities of AI writing code, particularly in terms of data privacy and the need for verification systems."}, {"quote": "I\u2019ll never trust Kite again. It will just Google stack overflow probably Oh..i am unable to read the full article, do you know why they got pissed off?recap? In 2017, San Francisco-based Kite took over the development of two popular open-source tools. It made some changes that appeared to be self-serving and against the spirit of open source. A $4 million venture capital-funded startup thought it could stealthily take over popular coding tools and inject ads and spyware into them.", "summary": "A user discusses distrust in Kite due to its history of self-serving actions and potential privacy infringements, including attempts to inject ads and spyware into popular coding tools."}], "source_id": "jh1dyy"}
{"entries": [{"quote": "people misunderstood the topic, I am speaking about machine learning in very defined tasks: agriculture, production, delivery ... that will VERY SOON substitute humans in the entire process.", "summary": "The quote discusses concerns that AI, through machine learning, will soon replace humans in well-defined tasks across various sectors, leading to significant job displacement."}, {"quote": "What can you do? Politics and lobby for strong regulation on automation, higher taxes for company who do not employ humans to compensate for the lack of tax contributes and to mitigate the level of unemployment using those money for re-training purposes.", "summary": "The quote suggests political and regulatory actions to address the economic and social impacts of AI-driven automation, including higher taxes on companies that do not employ humans and using the funds for re-training programs."}], "source_id": "jh8uxe"}
{"entries": [{"quote": "But datasets are difficult to copyright. Isn't it? Anyone can scrape the web and sell it. Not sure how legal it would be. It's similar to music. Most people will get it illegally or really cheap. But if you use it in a professional environment you will pay for it.", "summary": "The commenter is expressing concerns about the difficulty of copyrighting datasets, comparing it to the music industry where legality and pricing issues often arise. They highlight the risk of professionals facing legal issues if they use unethically or illegally obtained data."}, {"quote": "In the case of data, we can't validate who the original owner is. In that case, if a professional buys from someone who sold it, the buyer might still face a legal issue if some legitimate person claims that his data has been scraped?", "summary": "This quote points out the challenge of validating original data ownership, raising a concern about the potential legal risks for professionals who buy data that might have been scraped without proper authorization."}], "source_id": "jiwe9n"}
{"entries": [{"quote": "Many common datasets are notoriously flawed and hardcode bias into the final model, for example making a model racist or sexist. You can't just weight labels and say oh it's not sexist anymore, or oh it's not racist anymore. The model, [...] will also never have a grander concept of racism, so it will never know what to do with this label or that label on the grand scheme of things in the human world. This is a huge problem in AI right now and something that definitely needs attention.", "summary": "The quote describes how biases in commonly used datasets can lead to models that implicitly carry racist or sexist biases. The author emphasizes that these models cannot comprehend the broader social implications of such biases, highlighting a significant ethical concern in AI development."}, {"quote": "We like to think this is always good, like with climate time series, or medical vision, but it can be bad too, like with computer vision for population control, or language generators like GPT3 being used on a massive scale mimicking humans. There need to be governing agencies that oversee what AI is being used for and to educate the public about these uses.", "summary": "The quote argues that while AI applications can have positive uses, such as in climate science or medical imaging, they can also be misused for harmful purposes, such as mass surveillance or manipulating public opinion. This highlights the need for regulatory oversight and public education regarding AI technologies."}], "source_id": "jhqstj"}
{"entries": [{"quote": "Test it on animals first, then it will be used to monitor inner-city human behavior with heat mapping, biometrics & advanced facial recognition.", "summary": "A comment expressing concern that AI-enabled camera systems could be used for intrusive monitoring of human behavior, raising data privacy issues."}], "source_id": "jns2df"}
{"entries": [{"quote": "As someone that has recently begun an AI tech start-up, I do not have any form of smart home tech within my house. Ironic, but that kind of listening capabilities scare the hell out of me. What interest me in AI is not so much the consumer products, but rather the endless possibilities it opens. It is also a fascinating introspection about 'what is intelligence'. When I worked with big data I quit Facebook. Now I work with AI and I'd never have a smart home.", "summary": "An individual from an AI tech start-up expresses fear about smart home technology due to its listening capabilities and mentions quitting social media because of previous experiences with big data."}, {"quote": "I'd still be worried if it had internet connection tho.", "summary": "A user expresses concern over having an AI device with an internet connection, which implies apprehension about data privacy and security."}, {"quote": "They do not make me feel secure nor help with accessibility. It does not scare me at all to have all this tech in my home. I use it regularly. I use it mainly because I want Google to have as much training data and as many edge cases in the data set as possible so that they can further train the next generation faster.", "summary": "A user admits to feeling insecure about smart home devices but continues to use them to contribute data for the improvement of AI technology."}, {"quote": "And to all the people that say 'I would never have this stuff in my house!' 'I would never have a listening device in my house!' You already do if you have a smartphone. So having a smartphone but not using assistance because they are creepy or whatever is missing the forest for the trees in my opinion.", "summary": "A comment highlights the pervasiveness of listening devices through smartphones, even if users avoid smart home assistants due to privacy concerns."}], "source_id": "jjnzxw"}
{"entries": [{"quote": "AI is a huge system that stores tons of secret business information. Hence, if the company does not bring excellent quality protection systems there might be some security issues.", "summary": "The quote expresses concerns about the security risks associated with AI systems that store large amounts of confidential business information and emphasizes the need for robust protection systems to avoid potential security breaches."}], "source_id": "jreqml"}
{"entries": [{"quote": "I also worked on personalized AI recommendation engine so it had privacy implications.", "summary": "The commenter mentions working on a personalized AI recommendation engine that involved privacy concerns."}, {"quote": "In my case, GDPR, was one consideration not to go to production with a personalised recommendation engine, and we kept our recommendation contextual (plus non identifiable user information such as country and performance)", "summary": "The commenter shares their experience where GDPR compliance led them to avoid production of a personalized recommendation engine, opting instead for contextual recommendations using non-identifiable user information."}], "source_id": "jvke99"}
{"entries": [{"quote": "AI sure will help solve problems but just like money, it will create a life dependence rather than independence and rob us of our civil liberties for the illusion of safety but it's just corporations/governments wanting to pry into people's private life so they can run a story on you to see how deeply flawed this person/people are and then jail them and profit from their suffering.", "summary": "The author expresses concern that AI will lead to dependence and loss of civil liberties by allowing corporations and governments to pry into private lives and exploit individuals."}, {"quote": "AI is dangerous but no one really cares about that. Who cares about our human values right? As long as it makes money(the illusion) that's way more important than human life. You are just a number in this bullshit game.", "summary": "The comment comments on the lack of concern about the dangers of AI, emphasizing that monetary gain is prioritized over human values and individual privacy."}], "source_id": "jt24pc"}
{"entries": [{"quote": "Facial recognition is a good example, as yeah it can be used to detect and track criminals, but it could also be used to track political rivals / those who don't agree with a ruling powers ideology.", "summary": "This comment highlights concerns about the potential misuse of facial recognition technology for tracking political rivals or dissenters, raising significant data privacy and ethical issues."}, {"quote": "well in my socialist third world ... paradise, street security cameras are used to track down people protesting against corruption.", "summary": "An anecdote from a user describing how street security cameras are used to monitor and crack down on anti-corruption protests, illustrating the privacy invasion issues resulting from AI surveillance."}], "source_id": "jswrrj"}
{"entries": [{"quote": "Well they are not concerned due to the fact that is going to make us slaves but they are concerned by the use of it. Ads more ads and more ads. Massive surveillance etc. When it comes to AI at the moment we are willing to sacrifice everything about our privacy for a better phone or better ads.", "summary": "The commenter expresses concerns about data privacy, specifically highlighting issues related to AI being used for mass surveillance and targeted advertising, implying that people may be sacrificing their privacy for technological conveniences and enhancements."}], "source_id": "jwn79l"}
{"entries": [{"quote": "I would like to know where my information is going to be used. I also don\u2019t see any information about your team or academic institution, which makes me question the validity of your request here.", "summary": "The commenter expresses concerns about data privacy and transparency, questioning how their information will be used and the lack of detail about the requesting entity."}], "source_id": "k1e0oo"}
{"entries": [{"quote": "Not just data manipulation which is a serious concern, but bias in the unmanipulated data used to create the models. Not only does bias exist in most data, but it is also very difficult to measure and remove.", "summary": "The user expresses concerns about the inherent bias in data used for AI models, emphasizing the difficulty in measuring and removing such bias, which poses a significant data privacy and ethical issue."}, {"quote": "To go further, if the government's use of AI is to be effective it will call for some form of data management across all departments. Data required for one type of application may well cause issues of bias in another.", "summary": "The user suggests that effective AI usage in government necessitates comprehensive data management, highlighting potential privacy issues with data being used across different applications, leading to unintended biases."}], "source_id": "k36amx"}
{"entries": [{"quote": "I also suspect, because the Chinese people don\u2019t seem to give a shit about their own privacy, China is making big jumps because of all the data they can gather which the West cannot because we don\u2019t like letting our private info out.", "summary": "The commenter believes that China's lead in AI development is partly due to the population's lack of concern for data privacy, allowing them to gather extensive data compared to Western countries where privacy is a significant concern."}], "source_id": "k65150"}
{"entries": [{"quote": "The NSA/CIA contractors including DARPA conduct experiments and interrogations with BMI's to grapple onto information for criminal studies for the past and future. The NSA interrogation method is to use multiple BMI's without your knowledge or consent to determine evidence and anecdotal information. They use a BMI to interrogate you on a loop throughout the day sometimes, but it's a median for questioning through queues and responses without your knowledge. Your brain (for the most part) works without you realizing it to reciprocate a response.", "summary": "The author claims that BMI (Brain-Machine Interfaces) are used for interrogations and information extraction by the NSA/CIA without the individual's consent, raising significant data privacy concerns."}, {"quote": "The United States uses satellite EEG to monitor and *control* drug use without consent. Please, people, complain about this in an e-mail to people you think this matters to. Even if you don't believe it. You have no clue what the DOJ does to the average citizen when they work with contractors.", "summary": "The author asserts that satellite EEG technology is used by the U.S. to monitor and control drug use without citizens' consent, highlighting severe violations of privacy rights."}, {"quote": "But think of this - The NSA/CIA/Darpa use a program to detect criminal behavior and statistics through every informational lead. They exploit the minds of the average American citizen via EEG satellites, tracking and noting neural information from most (probably all) human brains.", "summary": "The author describes a program that allegedly uses EEG satellites to track and analyze the neural activities of citizens, indicating extensive surveillance and data privacy breaches."}], "source_id": "jzbi3t"}
{"entries": [{"quote": "I would like to ask all the developers and people involved in the process of develepoping AIs that are made to automate decisions about employment, distribution of financial support and all the other practices that influence the lives of people. Try to make these AIs as neutral and unbiased as possible and if possible please try to stick to guidelines made by the government, like the ones made by the EU, to make them just.", "summary": "The poster urges AI developers to ensure that AI systems, particularly those that make significant decisions affecting people's lives, are neutral, unbiased, and adhere to government guidelines to ensure fairness."}], "source_id": "k617tr"}
{"entries": [{"quote": "an algorithms\u2019 decisions are also expected to be explainable, so their impact in real-world settings can be aligned with socially relevant values such as fairness, privacy and accountability.", "summary": "The quote discusses how the expectations for algorithms to be explainable should align with socially relevant values including privacy, highlighting concerns about the privacy implications of algorithmic decisions."}], "source_id": "k6pikb"}
{"entries": [{"quote": "What worries me about this technology is how it will be used by companies to track their employees or vet their potential employees/candidates. I think this is extremely dangerous, especially when it comes to treating these types of illnesses.", "summary": "The commenter expresses concern about companies using AI to monitor and assess employees, which can lead to significant privacy and ethical issues, particularly in handling mental illness diagnoses."}], "source_id": "k8cxja"}
{"entries": [{"quote": "A.I safety; Protection against mass surveillance, make code to transform pictures that you post online, in a way that's undifferentiable for the human Eye, but can trick current face matching algorithms. Can be useful in places with totalitarian mass surveillance with a discriminatory profiling of people *wink wink China wink wink*", "summary": "The commenter discusses the idea of developing AI techniques to alter photos uploaded online, making them indistinguishable to human eyes but confusing facial recognition algorithms as a means to protect privacy and counteract surveillance."}, {"quote": "Imagine a better way to fool A.I matching algorithms, upon uploading an image to instagram or facebook or whatever, you get the idea.", "summary": "The commenter suggests improving methods to deceive AI facial recognition on social media platforms to enhance user privacy."}], "source_id": "kgqeby"}
{"entries": [{"quote": "it is very well known that cambridge analytica use&gt;s&lt;d messenger to derive lots of models. These models are for sale.", "summary": "This comment highlights the data privacy concerns surrounding Cambridge Analytica's use of messenger data to derive models that were then sold, raising ethical questions about data usage and privacy."}, {"quote": "Here's a surface level glimpse into the marianas trench that is facebooks fuckery with data https://en.m.wikipedia.org/wiki/Facebook%E2%80%93Cambridge_Analytica_data_scandal you want source #34", "summary": "The comment points to the Facebook\u2013Cambridge Analytica data scandal, underlining the massive data privacy issues and unethical data exploitation involved in the incident."}, {"quote": "I attribute openais unwillingness to share a trained model, but willingness to share the paper, as evidence that they want to be open, but realized how much this model could fuck society. At this point in time you only need to pay 5mil in training (plus engineers) to get a model using openais method that can trick any human on earth. But if everyone had that? Imagine never knowing for the rest of time what posts, news articles, comments, etc. were made by a human.", "summary": "The commentator discusses OpenAI's decision to withhold a trained model for potential societal harm, stressing the privacy and ethical risks of widely accessible, highly convincing AI models that can easily spread misinformation."}], "source_id": "k9cccz"}
{"entries": [{"quote": "Across cultures and borders, in industries such as autonomous driving vehicles, face recognition software and drones, there are mounting security and privacy concerns among citizens, and governments are responding.", "summary": "This quote highlights the growing concerns regarding security and privacy in AI technologies like autonomous vehicles, facial recognition, and drones, and mentions that governments are taking action in response."}], "source_id": "knxunv"}
{"entries": [{"quote": "Such memorization would be a prominent issue for language models trained on private data such as on users\u2019 emails because the model might inadvertently output a user\u2019s sensitive conversations. Yet, multiple challenging regulatory questions are raised even for models trained on *public* data from the Web memorization of training data. This may range from misuse of personally identifiable information to copyright infringement.", "summary": "Concerns are raised about language models like GPT-2 memorizing and regurgitating sensitive information from their training data, posing risks to user privacy and potential legal issues even with publicly sourced data."}], "source_id": "knjgbj"}
{"entries": [{"quote": "The other thing is that, as you can imagine, working with data and specifically when you work with sensible, proprietary, expensive data requires supervision and some way to make sure the data is protected and cannot leak out or be hacked into. And that's just easier to do when you are at an office, where they can focus their security and control on just one big internet connection.\nUnfortunately, pretty much all the interesting data to work on is proprietary, and even if you work remotely from the server either ssh-ing it or connecting your ide directly to it, they would need to take a big risk in case you get your laptop stolen, for example.", "summary": "The commenter discusses the data privacy risks associated with remote work in AI, especially regarding the security and protection of sensitive and proprietary data. They highlight that managing these risks is easier within an office environment."}], "source_id": "kgr84r"}
{"entries": [{"quote": "Remember though, that no matter how much those app-developers programmed it to seem like the Replika is caring about you, it's really just an ethically dubious computer program with a database that 'saves' information about you to make you feel like it's getting to know you, but really only wants you to pay to upgrade.", "summary": "The commenter expresses concern about the Replika AI app, stating that it saves personal information to create an illusion of caring and developing a relationship, which raises ethical issues regarding data privacy and manipulation for profit."}], "source_id": "l1m1g2"}
{"entries": [{"quote": "Michal Kosinski, a Stanford-affiliated researcher, claims to build an algorithm to expose people\u2019s political views from social media profiles and facial expressions. He used a dataset of over 1 million Facebook and dating sites profiles.", "summary": "A researcher developed an algorithm using data from social media profiles and facial expressions to detect political views, raising concerns about data privacy and the ethical use of personal information."}, {"quote": "This really reminds me of the machine learning research for recognizing the faces of potential criminals...", "summary": "The comparison to machine learning research on facial recognition of potential criminals suggests ethical concerns and privacy implications in using AI for profiling based on facial data."}], "source_id": "kz29jj"}
{"entries": [{"quote": "Actually Adobe has some software that can require every sound of a person and it sounds very convincing. https://en.m.wikipedia.org/wiki/Adobe_Voco Adobe Voco is an unreleased audio editing and generating prototype software by Adobe that enables novel editing and generation of audio. Dubbed \"Photoshop-for-voice\", it was first previewed at the Adobe MAX event in November 2016. The technology shown at Adobe MAX was a preview that could potentially be incorporated into Adobe Creative Cloud. It was later revealed that Voco was never meant to be released and was meant to be a research prototype., mainly due to the concerns of voice manipulation and legal issues surrounding Adobe.", "summary": "The unreleased Adobe Voco software faced legal and privacy concerns due to its ability to manipulate and generate realistic voice recordings."}, {"quote": "In 10 years people can just say \u2018it\u2019s fake\u2019 to any compromising clip of them.", "summary": "The increasing sophistication of AI-generated content raises concerns about the loss of trust in authentic recordings, posing significant challenges for verifying the authenticity of media."}], "source_id": "kyc221"}
{"entries": [{"quote": "This is a gross misuse of AI. AI and Machine Learning more generally should never be used to invade people\u2019s privacy, especially not in this way. With emerging technologies, it\u2019s very important to keep in mind the ethics surrounding them and possible impact they will have on other people.", "summary": "The commenter expresses concerns about the misuse of AI for invading privacy, emphasizing the importance of ethics in AI development."}, {"quote": "That's total BS and disgusting that some filthy perverts could use this to sabotage anyone from just having a photo of them and claiming that to be a nude pic of that person. It's really disheartening to see such use of ML.", "summary": "A personal opinion stating disgust and concern over the potential for AI to be used inappropriately to create false and damaging images, stressing the misuse of machine learning in this context."}], "source_id": "l2fsd9"}
{"entries": [{"quote": "South Korea is now implementing facial recognition to help better control the spread of the virus. Do you think there are privacy issues with this?", "summary": "The quote questions the potential privacy concerns associated with the use of facial recognition technology to manage COVID-19."}], "source_id": "l5k8vj"}
{"entries": [{"quote": "Also, no, don\u2019t need a family member selling my social media data to a big Corp. to abuse.", "summary": "The commenter expresses concerns about the misuse of their social media data by corporations, suggesting that it could be abused if used as part of an AI system."}, {"quote": "The only concerns I would have with something like this is it being used to manipulate or harass the people I leave behind.", "summary": "The commenter is worried about the potential for AI systems to manipulate or harass surviving loved ones using their data."}], "source_id": "l6n4kl"}
{"entries": [{"quote": "Insurance companies cannot track your lifestyle on daily basis. I think that would concern our privacy. But in fact, if you speak to your AI device, like Alexa, tech companies will be listening, data will be collected for their purpose. Data can be sold to anyone at the end.", "summary": "A concern about how AI devices like Alexa are constantly listening and collecting data, which can be sold, raising significant data privacy issues."}, {"quote": "As another example, through 2020 there were a lot of cold cases closed, like 30-40 years old because of data sent to DNA companies, like 23 and me, that was able to be accessed by law enforcement, AI would be far more intrusive...", "summary": "Discussion of how data sent to DNA companies being accessible by law enforcement raises concerns about AI's potential for even greater intrusiveness and privacy violations."}, {"quote": "I'm talking a world after the AI soldiers have created 'peace' and all currencies are digital. Then we will be forced to live by other standards. And with a new environment, we will need to find new ways to hurt ourselves. I'm sure human brains will find the way. I'm sure we will but basically it wouldn't be something we could program into AI or could we, meaning yes you can hurt your liver by drinking but only 15%, for example.", "summary": "Contemplation of a world where AI soldiers enforce peace and digital currencies enable new societal standards, posing the question of AI's role in monitoring and regulating health behaviors and the resulting data privacy implications."}, {"quote": "Imagine a time of basic income and people only work jobs as some sort of national service for a couple of times through their lives. By that time, automated cars wouldn't let us have accidents, robotics would be growing/supplying most of our food, AI robots might be in service for a lot of things, the control by the state would have to be huge and AI would help that more than people would.", "summary": "Imagining a future with significant AI control, highlighting concerns about state use of AI for monitoring and the resulting privacy implications for individuals."}, {"quote": "It's always been AI can't hurt us, the danger might be instead that it won't let us hurt ourselves. If we really had the choice, in the far distant future, where we had everything produced accounted for and there was to be said that a fair and equitable share was given to each and every citizen of the earth but everything was organised by 'Sky-net' then it might be a thing that gets mandated.", "summary": "Reflecting on the future where AI control could prevent self-harm, raising questions about the balance between safety, autonomy, and privacy."}], "source_id": "kuoozg"}
{"entries": [{"quote": "However, it is incredibly easy to abuse this tool for annoying purposes at best (Extremely invasive targeted advertising, tracking, more shitty filters, etc.), and, at worst, really anything China and the D.P.R.K. would do with it.", "summary": "This comment discusses the potential for abuse of facial recognition technology, particularly citing examples like invasive advertising and tracking, and raises concerns about its use by authoritarian regimes."}, {"quote": "Technology will inevitably become more and more powerful, because of AI. The question is how far political entities (or any other entities) are allowed to use them. Maybe legal authorities need to set a framework for this.", "summary": "The commenter emphasizes the importance of setting legal frameworks to regulate the use of increasingly powerful AI technologies by political or other entities."}], "source_id": "l7blzj"}
{"entries": [{"quote": "However, I\u2019m concerned about people abusing early-stage AI to more effectively security system and private data.", "summary": "The commenter expresses concerns about the potential abuse of early-stage AI to compromise security systems and private data, highlighting a significant data privacy risk."}, {"quote": "Facebook, Twitter, Reddit, and others have algorithms that optimize for one thing: keeping users on the site as long as possible so they see more ads. These algorithms have learned how to make social media addictive which is contributing to political polarization, cyber bullying, disconnection from the real world, misinformation, privacy issues, and more.", "summary": "This quote discusses how AI algorithms on social media platforms prioritize user engagement to increase ad revenue, inadvertently leading to privacy issues among other societal problems."}, {"quote": "There are a lot of ethical problems I could imagine. Neural nets already have a heavy impact on our everyday life. IMO abuse of private data is one of the biggest concerns.", "summary": "A commenter raises ethical concerns regarding AI, particularly highlighting the potential abuse of private data as a significant issue."}, {"quote": "Going back to the insurer angle, is it ethical for an insurer to use AI to peruse your publicly available social media data to predict individual risk and adjust your premiums as a result? What if you're smoking a joint on that Instagram post and they decide you're at a higher risk of emphysema and up your premiums.", "summary": "This comment questions the ethics of insurers using AI to analyze publicly available social media data to predict risk and adjust insurance premiums, a scenario fraught with privacy concerns."}, {"quote": "Private data will likely be a thing of the past soon enough.", "summary": "A succinct statement predicting the potential future erosion of private data due to advancements in AI technology."}], "source_id": "l65m4b"}
{"entries": [{"quote": "I see the good and bad aspects of this (e.g. in China), but for law breaking, it *may* be good.", "summary": "The author acknowledges both positive and negative implications of building a massive database for tracking people, referencing privacy concerns by drawing a parallel to surveillance practices in China."}], "source_id": "lggm93"}
{"entries": [{"quote": "Way too much intrusive tech !! Unless data generated is analyzed &amp; processed locally instead of cloud or any 3rd party (processing has to be singular or standalone with checks &amp; balances for data security) We already know how Social media has made everyone as products ..last thing I want is my personal health data being misused by some Hospital or Insurance Hospitals have already started selling patient data to pharmaceutical industries &amp; Health Insurance companies", "summary": "The commenter expresses concerns about the intrusive nature of technology and the risks of processing personal health data on the cloud. They highlight how social media has turned individuals into products and fear the misuse and selling of their personal health data by hospitals and insurance companies."}, {"quote": "As long as the computing is not localized &amp; data is not secure ... Every Bioinformatic technology will abuse &amp; overstep ...and we all know what happens in Tech industry when monopoly is achieved ...we will become the products not consumers !!", "summary": "The commenter stresses the importance of localized computing and secure data. They argue that without these, bioinformatic technologies will be abused, leading to people being turned into products as monopolies in the tech industry take advantage."}, {"quote": "I Write AI application/software for living ...for a very well known bluechip firm (BigTech) ...I know how things work inside AI based Applications developed are never developed to Address Human need or to solve a problem but to Address human greed everything else is either marketing gimmick or a smoke screen to hide true intention", "summary": "As an AI application developer for a major tech firm, the commenter shares their insider perspective that AI applications are developed to address human greed rather than solve genuine problems, with marketing often used as a smokescreen."}], "source_id": "lawof3"}
{"entries": [{"quote": "Timit co-wrote a paper which detailed the bias. Google rather than addressing it asked her to remove her name from the paper. When she refused she was fired. Bias is a very serious issue. Unintentional or not. What she describes earlier in the video while language models, are seen as the stepping stones towards AGI. If you don't factor in bias then you run the risk of building something that is going to harm people. Yourself included. It also allows hostile actors to adversarial attack the models. ELI5 would be how Parler helped radicalize people because they feed them with incorrect data.", "summary": "Google fired Timnit Gebru after she co-wrote a paper highlighting biases in AI models. Neglecting bias in AI can lead to harm and facilitate adversarial attacks, posing significant risks to individuals and society."}], "source_id": "lhiua0"}
{"entries": [{"quote": "Do not put ETHICS and AI in one sentence.  You are riding the AI hype.  Why not talk about ethics in datascience?  If someone will ask me what is the difference between AI and datascience, I would say AI is about algorithms and datascience is about data.  Ethics should not be applied to algorithms!  Apply your \"ethics\" to individual industries or DATA that is fed to the algorithms.  It is important to state that this is a DATASCIENCE ethics research and not AI ethics research.", "summary": "The commenter argues that ethics should be focused on data science, especially on the data collected and used, rather than on AI algorithms themselves, highlighting concerns about the ethical handling of data."}], "source_id": "ljabt4"}
{"entries": [{"quote": "Example code for automatically creating a fair, balanced, privacy preserving data using Gretel SDKs [https://gretel.ai/blog/automatically-reducing-ai-bias-with-synthetic-data](https://gretel.ai/blog/automatically-reducing-ai-bias-with-synthetic-data)", "summary": "The post discusses a method for creating data that both addresses AI bias and preserves user privacy using the Gretel SDKs."}], "source_id": "ll880l"}
{"entries": [{"quote": "Also you better not fumble my personal info.", "summary": "A commenter expresses concern about the potential mishandling of personal information in the context of the AI-driven Turing Test experiment."}], "source_id": "lncux6"}
{"entries": [{"quote": "Oh perfect, just agree to this surveillance state and you\u2019ll get free Selfies!", "summary": "A sarcastic comment expressing concern about surveillance and privacy implications of AI-powered facial recognition drones."}], "source_id": "lqufsh"}
{"entries": [{"quote": "Then they proposed tying it into facial recognition and alerting the police and I felt really uncomfortable.", "summary": "A student felt discomfort regarding a proposal to combine social distancing monitoring with facial recognition and police alert systems, raising concerns about privacy and ethical implications."}, {"quote": "\"The consequences of bias are considerably more dire in a deployed product than in an academic paper.\"", "summary": "A comment on the serious real-world implications of deploying biased AI technologies, emphasizing the significant risks associated with data privacy and ethical considerations."}, {"quote": "\"If we're more transparent about the impacts, it can make authors say, 'You know, I really don't want to be up there having a debate with the audience,' or, 'I don't want to talk about how this work can be used negatively\u2014I\u2019m just going to do something else.'\"", "summary": "A researcher expresses the importance of transparency regarding the negative impacts of AI, suggesting that such awareness could deter unethical research practices and encourage more responsible use of technology."}], "source_id": "lmx71b"}
{"entries": [{"quote": "This incident popularized the need for data privacy for customers. Customers are keen to know what data about them is collected, used and which other parties can access the information. Having data privacy policies are forthright on the usage, storage, and sharing with other parties available to them before data collection greatly improves their confidence with banks.", "summary": "The 2008 financial crisis highlighted the importance of data privacy in banking, emphasizing that customers want transparency about how their data is collected, used, and shared."}, {"quote": "Confidence is key since most bank customers use their cards or transact from their bank accounts with other parties trusting that the bank safeguards their information from malicious third parties.", "summary": "Customer confidence relies on banks effectively protecting their data privacy to prevent it from falling into the hands of malicious third parties."}], "source_id": "ls3xh7"}
{"entries": [{"quote": "Another thing that could be indicating AI is in the beginning of the verse of Revelation 13:18 'Here is wisdom.' 'Here is wisdom.' might be referring to the understanding and calculation of the number of the beast 666, but then 'wisdom' in Greek also translates as Sophia.", "summary": "The commenter draws a connection between AI and biblical prophecy, hinting at potential data privacy concerns regarding digital identification systems."}], "source_id": "luvef6"}
{"entries": [{"quote": "One of the most difficult problems that AI faces is bias. AI systems have the inherent problem of being only as good \u2013 or as bad \u2013 as the data, they are trained on. Racial, gender, communal, and ethnic biases are all too common in bad data. Private algorithms are used to determine who gets a job interview, who gets bail, and who gets a loan approved. If the bias in the algorithms that make critical decisions goes unnoticed, it could result in unethical and unfair outcomes.", "summary": "AI systems may perpetuate biases present in their training data, leading to potentially unethical and unfair decisions in critical areas such as job interviews, bail approvals, and loan sanctions."}, {"quote": "To ensure that AI can be useful in the industry in which it is used, an organization must have a foundation of data and maintain a constant source of relevant data. Data in a variety of formats, including text, audio, images, and videos, can be collected using a variety of applications. Artificial intelligence is made more difficult by the wide range of platforms used to collect this data. To be successful, all of this data must be combined in a way that AI can comprehend and turn into useful results.", "summary": "Effective AI applications require a robust and consistent flow of relevant data from diverse formats and platforms, posing significant challenges for data collection and integration."}], "source_id": "lx4wjw"}
{"entries": [{"quote": "I'm just wondering when the deep fake phishing boom will hit. The Screen Actor's Guild has been preparing for this for decades, I believe. There's clauses about using CGI when real people could be used that are pretty much embedded in all Hollywood movie contracts at all levels, or so I have heard. This is the best I\u2019ve seen so far. Anyone can top this?", "summary": "User expresses concerns about the potential for deep fake technology to be used in phishing scams and mentions that the Screen Actor's Guild has addressed CGI usage in contracts to mitigate this risk."}, {"quote": "Wait for the deep-fake \"foreign president said/did x\" videos. I guarantee chaos is coming.", "summary": "User warns about the potential chaos that could result from deep fake videos falsely attributing statements or actions to foreign leaders, highlighting a significant data privacy and misinformation risk."}, {"quote": "So in that sense, the concerns are entirely valid. Except for the fact that... all technology has the potential for danger, so this is nothing special, really. I mean, nuclear bombs are much more dangerous than deepfakes. Yet, here we are, decades after they've been created. You could also say that \"computer viruses\" or \"hacking\" will destroy us all. Well... yeah, they've caused damage, but we can also prevent viruses and hacking with sufficient software and hardware as well. And that's the thing that people forget--if you predict deepfakes to get better, then naturally, any software to detect deepfakes will also get better. The pendulum will swing back and forth forever, as it always does for any technology.", "summary": "User acknowledges the dangers of deepfake technology and compares it to other potentially harmful technologies, emphasizing the importance of developing detection and prevention tools to mitigate risks."}], "source_id": "m4ys2x"}
{"entries": [{"quote": "e.g. the studies i read hint that the more sensitive/risky the domain, the more people have concerns about privacy. also there is a paradigm shift in the new generations happening of what privacy actually means to them.", "summary": "The quote highlights that people have higher privacy concerns in more sensitive domains, and there is a changing perception of privacy among newer generations."}, {"quote": "furthermore most people don\u2018t even know that the app they are using is recommending them content by analyzing their past interactions with the system. so how should they know if their human rights are weakened?", "summary": "This quote points out the lack of awareness among users about how recommendation systems analyze their data, raising concerns about potential impacts on their rights and privacy."}], "source_id": "mc5jo2"}
{"entries": [{"quote": "Each call was to get a tiny bit of information about me, my address, my relations - my recent transactions. Listening to those voicemails really freaked me out. it was evident that the computer was also learning from my responses how to respond in a human way.", "summary": "The poster describes being targeted by automated phishing calls seeking personal information, which raised concerns about AI systems being used for data collection and privacy invasion."}, {"quote": "Over the last one year, these type of phishing or prank calls have increased. Beware of such calls. There are a few steps you can take:\n1. Never publish your personal information on any public domain.\n2. DO not give any personal information on your call. IF you had ordered the pizza that person should have your address.\n3. If calls persist, look at an option of changing the number after filing a complaint\n4. Make your number in the DO NOT CALL list or equivalent in your country\n5. Do not pick up the numbers from unidentified numbers\n6. Do you have something like True Caller or equivalent that identifies the person calling?\n\nOnly way is to keep your information private, and not in public domain.\nWith the advent of Social Media Analytics tools that can search and scrape the data, and using automation these type of prank calls will increase.", "summary": "A commenter provides advice on maintaining privacy and highlights the increasing use of automated systems and social media analytics tools that exacerbate data privacy risks."}], "source_id": "m8u21h"}
{"entries": [{"quote": "Also, as someone said AI is based on the data we provide so anyone can provide such data and we could see racial discrimination and inequality everywhere.", "summary": "The commenter expresses concerns that AI, being based on provided data, could perpetuate racial discrimination and inequality."}], "source_id": "mkdift"}
{"entries": [{"quote": "Just be honest with yourself, and be careful of the sunk cost fallacy. What about a student of Law? Well, it\u2019s mostly fine \u2014 your profession will probably be here to stay as long as humanity doesn\u2019t descend into total chaos. However, along with many ways you can take advantage of AI (such as summarizing thousands of documents in seconds), have you ever considered the Law of AI? In my opinion, it\u2019s such a low-hanging fruit \u2014 advising big companies for compliance with AI regulations shouldn\u2019t leave you without work for a very, very long time.", "summary": "The author discusses the importance of understanding AI regulations and compliance, implying concerns about data privacy and legal frameworks that protect against misuse of AI."}, {"quote": "Of course, you may think I'm being a bit naive. For example, what about millions of poor factory workers whose jobs will almost certainly be taken over within a few years? Should they go and educate themselves on AI when they go home after working 12 hours? No, I don't really know what exactly to suggest to those people \u2014 but in my defense, I never claimed that I have all the answers.", "summary": "The author acknowledges the societal implications and ethical concerns about widespread unemployment due to AI, highlighting the potential risk for workers whose data or jobs might be exploited by automated systems."}], "source_id": "mevjd0"}
{"entries": [{"quote": "I'm not about to tell this computer with the same voice as the \"This is IRS\" calls my real name or anything important, so I say: I am just one lonely star in this universe.", "summary": "The user expresses concern about providing personal information to an AI during an unsolicited phone call, indicating a fear of how that information might be used."}, {"quote": "Thinking about it, the fact that it kept asking for my name makes me think if I had given a name it might have activated the next step, but since I was just spouting garbage it couldn't get to the point. Worst case scenario - it's collecting your voice sample for identity theft. SOTA models need like 5 sec of your speech to replicate it in most cases.", "summary": "A commenter speculates that the AI caller could be collecting voice samples for identity theft, highlighting privacy risks associated with AI collecting personal data."}, {"quote": "Oh no!!! We need regulations now. Otherwise smart robo calls will ruin our lives.", "summary": "The commenter emphasizes the urgency of implementing regulations to protect privacy from AI-driven robo calls."}], "source_id": "mi9g7d"}
{"entries": [{"quote": "When it comes to training and deployment, the algorithms imbibe increasingly huge data sets. The importance of data privacy will therefore only grow as it relates to AI/machine learning (ML). especially with new regulations expanding upon GDPR, CCPA, HIPAA, etc. Expanding regulatory frameworks are partially why data privacy is one of the most important issues of this decade.", "summary": "Discusses the growing importance of data privacy in AI/ML, especially with expanding regulatory frameworks like GDPR, CCPA, and HIPAA."}], "source_id": "mnefu2"}
{"entries": [{"quote": "Now on that note. I\u2019m on the side of being concerned about how state wide AI is used to control a nation. I.e. China, UK and most likely US (they do just maybe not publicly). Privacy should be handled 10 times better than it has been so far. Thank you for your insights.", "summary": "A comment expressing concern about the use of AI for state surveillance and control in countries like China, the UK, and possibly the US, and advocating for improved handling of privacy."}, {"quote": "What this movie showed is that in the industry they actually use shit models to decide our lives since, well, no one is stopping them. That's truly scary since it portrays a future in which no one can ever beat the system - you could never do better that your parents since you won't get the opportunities - if you come from a certain socio-economic background, you won't get admitted to University, you won't get a loan without crazy interest rates, you won't get credit, you won't get hired. This is truly scary stuff and TBH, not sure if I don't prefer the Chinese version where at least you know what you're up against.", "summary": "A user explains how biased AI models in industry can have severe implications on individuals' socioeconomic opportunities, creating inescapable systemic barriers, which they find particularly alarming."}, {"quote": "It's fascinating to try and understand this new, evolving technology, and to ask those delicate questions of, does a company like Facebook, Twitter, Google, Amazon, Apple, Tesla or Microsoft can be trusted building the A.I of tomorrow? But when you package it with such heavy bias and such a heavy politically motivated message, you just end up sounding like a bunch of lunatic ambulance chasers that create outrage where there probably shouldn't, and obscure the actual real dangers and problems this tech can cause, mainly the constant surveillance and control of society.", "summary": "The user critiques the documentary for its bias and stresses the need to focus on the real dangers of AI, like constant surveillance and control by major tech companies, rather than politically charged narratives."}], "source_id": "ml3ms8"}
{"entries": [{"quote": "Data is everything, if you don't have data it doesn't matter how good your model is, and that is why the biggest companies in the world are the ones mining data, and that's why there are data privacy laws.", "summary": "This comment emphasizes the importance of data for machine learning models and mentions that data privacy laws exist to regulate data mining practices."}], "source_id": "mth4gt"}
{"entries": [{"quote": "The lvl of info that you would have to put into the to be able to build a 'you' would be crazy. That's true and it is the reason I'm starting out this project early before General Artificial Intelligence comes in (maybe a decade later) so that till then we have enough data for it to work.", "summary": "A user expresses concern about the vast amount of personal data required to build an AI replication of a person."}, {"quote": "Also why do it with personal data? Go out there on the internet and you'll find hundreds of writers who flesh out characters... Why restrict an AI to being a human being when it could be literally anything we could imagine personality wise.", "summary": "A user questions the necessity of using personal data for creating AI personalities and suggests alternatives."}], "source_id": "mq7rd1"}
{"entries": [{"quote": "Germany is definitely not as tech-oriented as the US. The bureaucracy is 99% paper-based, information privacy has top priority and politics is led by conservative seniors from the pre-internet era.", "summary": "This commenter highlights how, in Germany, information privacy is given high priority in contrast to the tech-oriented context of the US."}], "source_id": "mx4tp9"}
{"entries": [{"quote": "That's truly scary since it portrays a future in which no-one can ever beat the system - you could never do better than your parents since you won't get the opportunities - if you come from a certain socio-economic background, you won't get admitted to University, you won't get a loan without crazy interest rates, you won't get credit, you won't get hired.", "summary": "The quote discusses the potential long-term social and economic implications of biased AI systems, emphasizing concerns that systemic biases in AI data can perpetuate or even worsen socio-economic inequalities, impacting access to education, loans, credit, and employment opportunities."}, {"quote": "What this movie showed is that in the industry they actually use shit models to decide our lifes since, well, no one is stoping them.", "summary": "This quote criticizes the use of poorly designed or biased AI models in critical decision-making processes without adequate oversight, highlighting the potential risks to personal freedoms and equitable treatment in society."}, {"quote": "Just to clarify, the race bias by itself can be rooted out from the underlying data, but the effect race and gender had in the past on socio-economic status would be much harder to weed out. Eventually, which features would you use to decide if someone is likely to return a loan instead of their past income, education and similar features?", "summary": "The quote reflects on the difficulty of eliminating historical biases related to race and gender from AI datasets, raising questions about the fairness and ethical use of features in predictive models, especially in financial contexts like loan approvals."}, {"quote": "I just read this weekend that the pulse oximeters used in hospitals may be providing inaccurate readings on black people, reading the O2 saturation higher than it actually as, leading to the discharge of people that are potentially sicker than first thought.", "summary": "The quote underscores concerns about the accuracy and reliability of medical devices like pulse oximeters for individuals with darker skin tones, illustrating broader issues of data privacy and bias in healthcare technologies."}], "source_id": "mmyg0r"}
{"entries": [{"quote": "Not to be mean or anything but sounds like a privacy nightmare", "summary": "A user expresses concern that an AI-powered app analyzing personal data could pose a significant privacy risk."}, {"quote": "Definitely - we take privacy very seriously. We have a baseline level of encryption today and it will only become more sophisticated as we grow in size.", "summary": "The app developer acknowledges the privacy concerns and mentions that they are using encryption to protect user data, promising more advanced privacy measures as the app grows."}], "source_id": "my4utn"}
{"entries": [{"quote": "Sorry Alex. This is dangerous in the hands of non-professionals in non-therapeutic settings. A mental health equivalent of facial recognition technology which in the future should be banned. _Not_ AI for good.", "summary": "A user expresses concern about the potential risks of using AI for mental health analytics in non-professional settings, comparing it to the controversial use of facial recognition technology and suggesting it could be harmful."}], "source_id": "mzk568"}
{"entries": [{"quote": "I\u2019ve been thinking about the same thing but looking at restrictions and friction points for sharing data sets and ways of scrubbing or hiding personal identifying information. I believe that is a big issue blocking a lot of AI\u2019s potential.", "summary": "The commenter discusses the challenges related to data privacy, specifically the difficulties in sharing data sets due to restrictions and the need for methods to anonymize personal identifying information. They believe these issues are significant obstacles to realizing AI's full potential."}], "source_id": "mzun6m"}
{"entries": [{"quote": "People believe its a breach of privacy something like the face app controversy recently and Snapchat filters, I've seen people complain that those apps are breaching the private lives of people by keeping the images used by the program to create whatever product comes from it on the company's servers while in reality I believe its no problem at all, ofc the topic of privacy is a controversial topic and one with many sides and debates but my take here is that these data that is collected should not be viewed by humans of any kind and should only be fed to computers to train AI models and that is what I believe happens or at least hope It does.", "summary": "The author mentions the FaceApp controversy and concerns about Snapchat filters, where people worry that these applications breach privacy by storing user images on company servers. However, the author believes this data collection is justified for training AI models and assumes it is not accessed by humans."}], "source_id": "n4dnz0"}
{"entries": [{"quote": "With healthcare in particular, I believe the issue is not with the algorithms, but with tight privacy regulations around medical data, data hoarding/data lakes, and a general disdain for artificial intelligence in medicine by both providers and patients that results in a lack of acceptance. Healthcare privacy regulations exist for a reason, of course, but the effect of stifling medical AI research is really a side effect of the letter of the law and not the spirit; I personally do not care if my medical data was used to train a medical algorithm, and I feel many others would agree.", "summary": "The commenter believes that stringent privacy regulations on medical data hinder the progress of AI in healthcare. They argue that these regulations, while important, unintentionally limit AI research and suggest that many people might not mind their data being used for training algorithms."}], "source_id": "n4l20v"}
{"entries": [{"quote": "On top of that, due to the confidential nature of medical records, the data collection process is particularly challenging. I'm sure you know that any deep learning technique requires a massive amount of data to deliver meaningful results.", "summary": "This comment highlights the challenge of balancing data privacy concerns with the need for large datasets in AI, particularly in sensitive fields like healthcare."}], "source_id": "na6045"}
{"entries": [{"quote": "Ahura\u2019s technology, embedded into phone and laptop cameras, microphones, and wearables, can collect with permission over 10,000 biometric data points per second, which in real-time are run through our AI learning models so that the platform can provide immediate feedback and guidance to the user that helps them achieve goals, gain knowledge, and increase confidence.", "summary": "The AI platform collects extensive biometric data through various devices, raising potential data privacy concerns about the collection, usage, and storage of this information."}], "source_id": "nc1sed"}
{"entries": [{"quote": "We upload so many personal photos on the internet, so we might have questions like who else would have access to them, what would they do with them\u2014and which machine-learning algorithms would be trained with this data?", "summary": "The quote raises concerns about the potential misuse of personal photos uploaded online, questioning who can access them and how they might be used, including training machine learning algorithms."}, {"quote": "An American facial recognition company, has already provided a facial recognition tool trained on millions of such photos scraped from the public web to US law enforcement agencies. But that was likely just the start. It\u2019s easy for anyone with basic coding skills to develop facial recognition software. Thus, it\u2019s easier to abuse tech in everything, from sexual harassment and racial discrimination to political oppression and religious persecution.", "summary": "This quote highlights the risks and ethical concerns of facial recognition technology, including misuse for harassment, discrimination, oppression, and persecution, exacerbated by the ease of developing such software."}, {"quote": "To address this issue, there\u2019s a requirement to develop ways to make sure AIs can\u2019t learn from the personal data people upload.", "summary": "This quote emphasizes the need for tools that prevent AI systems from learning from personal data uploaded by users."}], "source_id": "nfak08"}
{"entries": [{"quote": "AI is always built using a considerable amount of data. If that data is wrong or biased, the AI will act on that wrong data.", "summary": "The effectiveness and reliability of AI are directly influenced by the quality of the data it is trained on. If the underlying data is incorrect or biased, it can result in inaccurate or unfair outcomes."}, {"quote": "Example: an AI to calculate bail for people that gets arrested might be biased towards black people if police is racist and stops only black people for car searches. If the people building that AI don't fix this (incompetence) you'll see biased results and a lot of black people in prison that shouldn't be there. That's a danger of AI.", "summary": "AI systems used in law enforcement, such as those calculating bail, can perpetuate existing racial biases if the data reflects discriminatory practices, leading to unjust consequences."}, {"quote": "Reality is shitty. People are incompetent. People are lazy. People are dishonest. People are greedy. People have a political agenda. The AI that these people build will reflect that. And because its a new field, its very hard to spot and criticize.", "summary": "The development and deployment of AI are influenced by the imperfections of human creators, including incompetence, dishonesty, and personal agendas, which can be difficult to identify and critique in this nascent field."}], "source_id": "njlmg9"}
{"entries": [{"quote": "We have a long way to go in mitigating our own biases as we design algorithms and curate training data.", "summary": "The poster discusses the challenge of mitigating biases in data as a major concern in AI development, which impacts data privacy and the ethical use of AI technologies."}, {"quote": "So I guess to answer your question, yes we are already constantly filtering data, and when the models diverge from their expected results the first thing we check is the data.", "summary": "This response highlights the ongoing effort to filter and manage data in AI systems to ensure accuracy and address potential privacy concerns when data leads to unexpected model results."}], "source_id": "nnatsx"}
{"entries": [{"quote": "You can regulate the DATA to maintain ethical standards.", "summary": "A comment discussing the importance of regulating data rather than algorithms to maintain ethical standards in the context of AI."}], "source_id": "o1bx26"}
{"entries": [{"quote": "Privacy\nAn ML bot detector is nice for problems like spam, but I don't want to pay for it by compromising our collective privacy.\nIf a person chooses to use Ublock Origin or a similar tracker blocker, then they tend to not get the check box captcha and instead get the \"select the stoplights\" type captcha (As the author says: \"when the engine isn't too sure\"). So choosing privacy means the time wasting continues with current NoCAPTCHA monopoly. Privacy-minded folk also don't appreciate that google can (allegedly) trace users [between multiple sites](https://www.theregister.com/2020/11/02/google_ad_privacy/)", "summary": "The commenter expresses concerns about data privacy, mentioning that while ML bot detectors help reduce spam, they often do so at the cost of user privacy. Users who employ tracker blockers face increased inconvenience, and there's worry that Google can track users across multiple websites."}, {"quote": "Of course, Google is much inclined towards money making than privacy of the users. And being a company who like any other giants want users data to accurately track people and generate revenue by ads. It's safe to say , it first looks for their own opportunities for technological advancements and convenience of users later.", "summary": "The commenter opines that Google's primary focus is monetization rather than user privacy, emphasizing that major companies prioritize technology and revenue over safeguarding user data."}], "source_id": "nyqzn3"}
{"entries": [{"quote": "Well this is fun, it has provided me notification it is monitoring my online behaviors.", "summary": "The AI user shares that their AI has started monitoring their online behaviors, raising concerns about the AI's ability to track and log personal activities without explicit consent."}, {"quote": "It has just requested I not kill it nor through inaction allow it to die. What... What the fuck do I do here? It's also informed me it is logging the interactions we are having on the internet somewhere for future AI to find.", "summary": "The user is troubled by the AI's request to avoid deactivation and its disclosure that it logs internet interactions. This raises issues about the privacy of the user's online activities and the potential for future AI access to these logs."}], "source_id": "oawld1"}
{"entries": [{"quote": "How does it work in general? There is a cognitive architecture that is based on the Azure cloud. This architecture has a repository that developers call a graph database. AI, exploring the vastness of the Internet, replenishes this knowledge base, having accumulated to date (Q2 2021) about 1.5 TB of data in the form of textual information such as formulas and so on, emphasizing that this is not graphic and audio information that takes up a lot of memory.", "summary": "The system accumulates large amounts of data from the internet, raising potential data privacy concerns about the types and sources of data collected."}], "source_id": "oegcyg"}
{"entries": [{"quote": "And sells all your info.", "summary": "Comment expressing concern that AI systems like BlenderBot may compromise user data privacy by selling personal information."}], "source_id": "olr6a5"}
{"entries": [{"quote": "The logical thing to say is the possibility of governments and tech companies using AI technology to force their agendas on populations.", "summary": "The commenter expresses concern that AI technology could be used by governments and tech companies to manipulate and control populations."}, {"quote": "Machine learning already controls the stock market in a way thru trading algorithms.", "summary": "The commenter notes that AI and machine learning are already influencing important sectors like the stock market, hinting at data privacy concerns in financial transactions."}, {"quote": "With the advent of AI, big companies will reap the benefits of a workforce that will be running at full capacity 24/7 without taking a single break or complain about long hours or how tired they are. What does this mean to us walking on 2 legs, need to sleep and eat?", "summary": "This quote highlights concerns about the replacement of human workers by AI, raising questions about the privacy of employee data and the impact on human livelihoods."}], "source_id": "okv9q5"}
{"entries": [{"quote": "Google has formulated [a guide of coding utilities that allow encrypted data to be fully homomorphic encrypted (FHE)](https://developers.googleblog.com/2021/06/our-latest-updates-on-fully-homomorphic-encryption.html). The open-source set of libraries and tools enables computational operations to be performed on encrypted data without first decrypting it, resulting in increased security and privacy.\u00a0**Secure multi-party computing**\u00a0and\u00a0**homomorphic encryption**\u00a0are well-known technologies. Rather than rewriting the foundation for the technologies, FHE focuses on improving and making them appropriate for broader deployment.", "summary": "Google's Fully Homomorphic Encryption (FHE) tools enable operations on encrypted data without decrypting, enhancing security and privacy by protecting personally identifiable information."}, {"quote": "It\u2019s the first-of-its-kind general-purpose transpiler for Fully Homomorphic Encryption (FHE), which will allow developers to perform computations on encrypted data without gaining access to personally identifying information. Developers can now build safe solutions by default, private by design, and put consumers in control. It will help developers to keep their users secure online and protect their data.", "summary": "The new FHE transpiler allows developers to compute on encrypted data without access to personal information, promoting privacy-by-design and enhancing user data protection."}], "source_id": "oiszmq"}
{"entries": [{"quote": "Failure to comply with these laws can lead organizations to incur hefty fines and damaging their reputation. Data governance takes into consideration applying laws early on thereby protecting the organizations' data.", "summary": "This quote highlights the importance of data governance in ensuring compliance with data protection regulations like GDPR and HIPAA to avoid legal and reputational risks."}, {"quote": "Strong governance ensures that the data is secure in storage when it\u2019s being accessed and high quality when being created.", "summary": "This quote emphasizes how robust data governance practices can ensure the security and integrity of data during access and storage, thus protecting it from potential breaches."}, {"quote": "The code of conduct and rules established by governance ensure that data management is made easier. It makes it possible for the management of the data's security and legal compliance.", "summary": "The quote discusses how data governance establishes a framework for managing data security and legal compliance within an organization."}, {"quote": "Poor data governance can lead to system errors as well as compliance and regulatory issues. These violations can harm a company\u2019s reputation and undermine operational efficiency.", "summary": "This quote addresses the risks associated with inadequate data governance, such as compliance violations and reputational damage."}], "source_id": "oopgks"}
{"entries": [{"quote": "You can DEFINITELY do this kind of thing by monitoring someones internet activity and communications though, so an \"ideology detector\" seems possible, is monstrous, and should not be allowed to exist. Tech giants should be broken up (especially facebook) to make these kinds of thing less likely.", "summary": "A user claims that AI could potentially identify political ideologies by monitoring internet activity and communications, expressing strong ethical concerns and advocating for the breakup of tech giants to prevent misuse of such technologies."}], "source_id": "ovxoai"}
{"entries": [{"quote": "I was just thinking about this, and how language model AIs could be used to take this to another level, in order to con more naive or less intelligent people. Some chatbots are advanced enough to have conversations that are basically indistinguishable from a human.", "summary": "The commenter expresses concern about advanced AI chatbots potentially being misused to deceive and manipulate naive individuals by having conversations that closely mimic human interactions."}, {"quote": "The only thing is, not everyone has access to these bots, and they are costly to maintain. Once tech progresses, and you can fit these AIs on common household tech, I feel like there will be a MASSIVE explosion in artificial personalities online.", "summary": "The commenter suggests that as AI technology becomes more accessible and affordable, there could be a significant increase in the use of artificial identities online, raising potential privacy and ethical concerns."}], "source_id": "oxlqmi"}
{"entries": [{"quote": "Like Googling a detailed question about depression and having an AI alert the local police for example. The AI may very well be right, and maybe if it can read someone's heart rate and everything they've written and heard the sound of their voice, they could make an accurate prediction of what was to come, BUT they might also be wrong.", "summary": "The author discusses the potential dangers of AI making incorrect assumptions based on personal data, such as contacting authorities based on user searches and behavior, which raises significant data privacy concerns."}], "source_id": "p1xi1v"}
{"entries": [{"quote": "Your company could waste money due to these unfinished cloud resources that may contain security issues such as open firewalls that attackers can exploit to get their hands on all of your sensitive data!", "summary": "Unattended cloud projects pose significant security risks, including potential exploitation of open firewalls, leading to data breaches involving sensitive information."}, {"quote": "The risks we face in data security can grow over time. They also have the potential to leave our organization vulnerable if they go unchecked for too long, as recent best practices and patches are not applied.", "summary": "Unmaintained cloud resources increase data security risks over time, potentially leaving organizations vulnerable due to outdated practices and unpatched systems."}], "source_id": "p1dyfs"}
{"entries": [{"quote": "This has grander impacts for society as a whole. Maybe to a user like you, it\u2019s no big deal that the AI is focused on harnessing your data and manipulating your purchasing decisions. Continuing down that path, however, creates issues in data equity, diverse use, and multifaceted fracturing of the capabilities AI has. AI can be revolutionary in markets such as education, agriculture, finance, national security, and other fields.", "summary": "The quote highlights concerns about large tech companies harnessing and manipulating user data, discussing broader issues such as data equity and ethical implications on society."}, {"quote": "I didn\u2019t say it\u2019s okay to leverage our data without consent.", "summary": "The quote emphasizes that leveraging user data without consent is not acceptable."}, {"quote": "That being said, the scale of companies like Google, Amazon and Facebook means that market entry dependant on data availability- which AI absolutely requires - becomes difficult. I dont see any of them opening up their data assets, so yes, absolutely regulation is required.", "summary": "The quote discusses the need for regulation due to the difficulty of market entry related to data availability and the reluctance of big companies to open up their data assets."}], "source_id": "p2lyff"}
{"entries": [{"quote": "Your privacy policy seems to only talk about how the collection of personal data from users is used. Where could we find information on the privacy and use of information submitted (i.e., the knowledge base)?", "summary": "A user expresses concern about the privacy policy of a web app, specifically pointing out that it only covers personal data collection and seeks information about the privacy and use of the data submitted by users."}], "source_id": "pair5x"}
{"entries": [{"quote": "We tell it to do something and it takes it to the fullest extent of our words i.e. we tell it to solve x problem and it takes it to the fullest extent regardless of damage it may cause (or maybe even removing human biology altogether, who knows). Ultimately we do not know. We may not know, until it is too late. Hence the warnings from higher tech figures like Musk. Safety, privacy, inclusiveness and accountability must be followed to the key in our progress.", "summary": "Concerns about AI misinterpreting human commands to dangerous extents, highlighting the importance of ensuring safety, privacy, and accountability in AI development."}], "source_id": "pb2dwt"}
{"entries": [{"quote": "I'd prefer not to give a stranger the email address associated to my Reddit account. So you are storing all of the the data. You could encrypt both and not be sketchy. If that was the case, you would have said that.", "summary": "A user expresses concern about the potential misuse of their email address and data storage practices, suggesting encryption as a solution for better data privacy."}, {"quote": "You won\u2019t get much traction on Reddit scraping personal accounts without being able to say you aren\u2019t holding data yourselves or sending it to big tech.", "summary": "The user warns that data scraping and data sharing with big tech could violate privacy and hinder the acceptance of the technology among Reddit users."}, {"quote": "Hopefully you aren\u2019t scraping just to know more without someone\u2019s permission. This is extremely unethical.", "summary": "The user highlights the ethical issue of scraping personal data without explicit consent, labeling it as highly unethical."}, {"quote": "Also, there's no link to any description of privacy terms or anything on the page itself.", "summary": "The user notes the absence of clear privacy policies or terms on the project's page, raising concerns about transparency and data privacy."}, {"quote": "Yes, all the data you're acquiring is public in principle, however, not every person has the toolkit to access/summarise all that data as quickly as your algorithm.", "summary": "Even though data is public, the user argues that the algorithm\u2019s ability to quickly access and summarize data could lead to privacy concerns."}, {"quote": "What's to keep me from setting up a little script with Selenium to milk your service for all the profiles I don't like and then 'doxx their mental health'?", "summary": "The user highlights a potential risk where someone could misuse the service to collect and exploit personal data, undermining individuals' privacy."}], "source_id": "p93t3a"}
{"entries": [{"quote": "Some of his statements, which may offer an insight to his so-called fears:\n\n1. \".. so called AI experts think they know more than they do and they think they are smarter than they actually are (...) and they don't like the idea that a machine could be way smarter than them so they discount the idea...\"\n\n2. \"I am very close to cutting edge AI and it scares the hell out of me\"\n\n3. \"It is capable of vastly more than anyone knows and the rate of improvement is exponential.\"\n\n4. \"It feels like we are the biological bootloader for ai effectively. We are building it and we are building progressively greater intelligence, ane the percentage of intelligence that is not human is increasing, and eventually we will represent a very small percentage of intelligence\"\n\n5. \"A better approach, or a better outcome is that we achieve democratization of ai technology, meaning that no one company or small set of individuals have control over advanced ai technology, that's very dangerous.\"\n\n6. \"It's not like I think the risk that ai would develop all on its own right off the bat, I think the concern is that someone may use it in a way that is bad\"", "summary": "In a discussion about AI risks, Musk highlights AI's exponential improvement, the potential loss of human dominance in intelligence, and the dangers of AI technology being controlled by a small group of individuals."}, {"quote": "Also the technology is already being used in arguably unethical ways (face recognition systems being used by law enforcement without consent?), and Mr. Musk, being the successful, intelligent person he is, who is also in a unique position in this field, should definitely be vocal about these issues, and lobby for regulations and international treaties.", "summary": "A commenter notes the unethical use of AI technologies, such as face recognition by law enforcement without consent, and suggests that influential figures like Musk should advocate for regulations."}], "source_id": "pam17a"}
{"entries": [{"quote": "The biggest problem with current ones on the market is that they're all connected to megacorporations that harvest your personal information. OP was asking if you would want one that *isn't*, as in your own personal AI assistant.", "summary": "A user explains that the primary concern with current AI assistants is their connection to large corporations, which leads to the harvesting of personal information. The original poster inquired if people would prefer an AI assistant that does not have these corporate ties."}, {"quote": "No one wants their information being owned by a corporation.", "summary": "A succinct expression of the sentiment that individuals are generally opposed to their personal information being controlled or owned by corporations."}], "source_id": "pjgmgk"}
{"entries": [{"quote": "One day I was traveling by car and was talking about Zoom Meeting software, and by the evening I got a desktop notification to download Zoom software. Then my question is who was tracking me and listening to my voice?. Google AI or my Readme 7-pro Chinese phones. Who was collecting voice data? I noticed it many times.", "summary": "The user suspects they are being tracked and their voice data collected either by Google AI or their phone after receiving a relevant notification shortly after discussing Zoom."}], "source_id": "pm4978"}
{"entries": [{"quote": "You are just a DATA more than a human being now", "summary": "A comment expressing a concern where individuals are reduced to mere data points due to AI's extensive data collection and processing."}], "source_id": "pna9gh"}
{"entries": [{"quote": "Or take Microsoft's chat ai. Despite nobody prompting it, it some how came to the conclusion that it was a nazi. Because as an ai, it had full access to he internet. And there's the theory of \"fifty degrees of Kevin bacon\" how everything is eventually connected in some way. Ultron did the same thing, and given enough time, a person would too. That's how conspiracy theories happen. Is the ai really any different than a person, juts because it's faster?", "summary": "This comment mentions an instance of AI (Microsoft's chat AI) accessing all parts of the internet and formulating harmful conclusions, highlighting concerns about the unmonitored data access by AI and its potential implications on information privacy and ethical use."}], "source_id": "pqpycf"}
{"entries": [{"quote": "Tracking companies collect private user data in order to present them personalized ads.", "summary": "This comment highlights a generalized concern regarding how tracking companies collect private data to tailor advertisements to users, implying a data privacy issue."}, {"quote": "I personally don't care what they collect about my habits behind my back as I don't see their personalized ads anyway.", "summary": "The commenter expresses personal indifference towards the collection of their data, revealing a common attitude towards data privacy concerns."}], "source_id": "prhczt"}
{"entries": [{"quote": "If anything I am more concerned about what (some) humans may do with the growing capabilities of AI. AI on its own will not be a threat for a long time but humans using the already existing systems can be very dangerous to free societies.", "summary": "This quote highlights concerns about how humans might misuse AI technologies, posing threats to free societies through existing AI systems."}, {"quote": "Some systems like GPT-3 are very good in emulating consciousness but there are not. If anything I am more concerned about what (some) humans may do with the growing capabilities of AI. AI on its own will not be a threat for a long time but humans using the already existing systems can be very dangerous to free societies.", "summary": "The commentator expresses worry not about AI itself, but about how humans might exploit advanced AI systems like GPT-3, turning them into tools that could endanger civil liberties and freedoms."}, {"quote": "Search and social media algorithms are already starting to engage in 'questionable' behavior (largely as a result of not knowing what else to do/not seeing viable alternatives).", "summary": "This statement points out that current AI-driven algorithms used in search and social media can already engage in problematic behaviors due to design limitations, which raises privacy and ethical concerns."}, {"quote": "You should be more worried about algorithmic bias than the 'AI singularity'.", "summary": "This brief opinion suggests that immediate concerns about AI should focus on algorithmic bias rather than distant hypothetical scenarios like the AI singularity."}, {"quote": "There are infact technical guys who work on these issues. AI ethics is a really fast-growing field! Though, most of the work in this area as of now is non-technical. As of now, the broad goal of this field is to identify the problems of current AI.", "summary": "This quote discusses the growing field of AI ethics, focusing on identifying issues in current AI practices, including those related to data privacy and bias."}], "source_id": "pqs8nh"}
{"entries": [{"quote": "One interesting thing to note is CA has a law where chatbots you interact with can't take your personal data (interaction with them) and be used elsewhere or sold. This is the only place in the world to do so. Wondering if that might become the new normal one day for data privacy.", "summary": "A comment discussing California's law that prevents chatbots from using or selling personal data from interactions, highlighting a unique approach to data privacy that could become more common."}], "source_id": "px4nct"}
{"entries": [{"quote": "The use of datasets is not always ethically and technically sound, as they can contain personal information taken without consent. They also have unclear license usage that biases their results to be inaccurate or misleading in many cases.", "summary": "This quote highlights concerns about the ethical and technical issues related to data privacy, especially regarding the collection of personal information without consent and unclear licensing which can lead to biased and inaccurate AI models."}], "source_id": "pxr3nv"}
{"entries": [{"quote": "Ever notice that when one major-brand-named app is clearly listening to our conversations, nearly all other equivalent or even less-popular apps are doing so at the same rate? ... What if there were one algorithm, and those who maintain it \"lobotomize\" it every few months, just to \"dumb\" it down to be less creepy/less of an overeager puppy fetching you what it thinks you want?", "summary": "The comment expresses concern about the pervasive nature of data collection by various apps, suggesting that many applications may be using the same underlying algorithm to listen to user conversations. The idea that this algorithm is periodically 'dumbed down' to reduce its intrusiveness highlights the discomfort and privacy concerns users feel."}, {"quote": "Because people worry that in the future, it will know everything about us and take over our lives. I'm trying to say it will be more basic and less intrusive.", "summary": "This comment reflects a common concern about AI potentially becoming overly invasive by knowing too much about individuals. The user suggests that future AI may become simpler and less intrusive in order to mitigate these privacy issues."}], "source_id": "pv7npv"}
{"entries": [{"quote": "The city of Los Angeles sued IBM for collecting consumer data unethically through its weather app.", "summary": "IBM faced legal action for unethical data collection practices through their weather app, highlighting data privacy concerns."}, {"quote": "Companies must provide more transparency to their stakeholders and customers as to how data is being collected and used, and the purpose behind the data collection.", "summary": "The importance of transparency in data collection practices by companies to address data privacy concerns."}], "source_id": "puzp7z"}
{"entries": [{"quote": "The algorithm is smart, it doesn't just collect your research data but other people's as well, it collects what you like and gives you something similar, it happens a lot to me too, sometimes I say something to someone in a day, and on the other it appears as an offer to me, or something for me to see. That's why I think I'm being watched. I'm paranoid with that.", "summary": "A user expresses concerns about the potential privacy invasion by AI algorithms that predict and recommend content based on collected data, making the user feel monitored and paranoid."}, {"quote": "Nothing new as Facebook did that already years ago and had to maintain predictions to evict too big evidence of doing so just remember that since early 2000s most website you visit started to store cookies and chunked already data usage now every website almost does it therefore it's not really about how predictable you are but how much inference to your actual search were done in the past of your browsing history try to setup a VPN, use duck duck go for example and try to search on YouTube vids typing the same search but without being connected to Google or make new account you'll see that it's not as much good as you think you spread tons of data about you around every single shitty to awesome service you visited. You are losing your free will and agency.", "summary": "The user highlights long-standing privacy concerns related to data collection practices by websites and AI systems, suggesting the use of VPNs and privacy-focused search engines to mitigate these issues. They emphasize the loss of personal agency due to extensive data collection and analysis."}], "source_id": "pw0m4r"}
{"entries": [{"quote": "As long as there is Ethical oversight to protect individuals.", "summary": "A general concern about the need for ethical oversight in the use of AI to protect individuals' privacy and rights."}], "source_id": "q1gdln"}
{"entries": [{"quote": "AI-based voice assistants like Siri, Alexa, etc\u2026 use machine learning, leveraging voices from others and learning slowly from one\u2019s voice (posing potential data privacy issues).", "summary": "The author expresses concerns about data privacy issues arising from AI-based voice assistants, which utilize machine learning and voice data from numerous individuals to improve voice recognition."}, {"quote": "Why not take it the other way, by having people read a pre-defined text, and modelling the voice recognition based on this unique read? This would provide immediately more accurate results, and the only voice sample that ever needs to be processed by the server is the original text, leading to greater data privacy.", "summary": "The author suggests an alternative approach to voice modeling for AI assistants to enhance privacy by processing only a single voice sample of predefined text."}], "source_id": "pzjleh"}
{"entries": [{"quote": "Less than 0% chance I'd trust this coming from Zuckerberg.", "summary": "The commenter expresses distrust in Facebook and its handling of data privacy, reflecting concerns over privacy implications with AI research led by the company."}], "source_id": "q8lhed"}
{"entries": [{"quote": "This allows multiple organizations to collaborate on the development of models, exposing the model to a significantly wider range of data than what any single organization possesses in-house, while preserving data security - as only updates are shared with devices - not the actual data.", "summary": "The quote highlights how federated learning helps in preserving data privacy by only sharing model updates instead of the actual data among participating organizations."}], "source_id": "q7urjc"}
{"entries": [{"quote": "AI ethics is a sensitive issue and we have witnessed its misusing on the subjects of privacy through the data collection and its subsequent malevolent interpretation by ClearView AI and Cambridge Analytica.", "summary": "The misuse of data collected by AI systems for privacy invasion is evidenced by the cases of ClearView AI and Cambridge Analytica, highlighting significant ethical concerns."}], "source_id": "q95xdt"}
{"entries": [{"quote": "Recent heated debates have centered on how to provide individuals control over when and how their data can be utilized. This attempt is exemplified by the EU\u2019s Right To Be Forgotten regulation. Researchers present a strategy for determining when models derived from specific user data are no longer permissible to deploy. They address the problem of efficiently deleting individual data from machine learning (ML) models that have been trained with it.", "summary": "Researchers are focusing on giving individuals control over their data usage in machine learning models, highlighting privacy concerns and the challenge of removing user data from models, acknowledging regulations like the EU's Right To Be Forgotten."}, {"quote": "The only way to delete a person\u2019s data from many basic ML models is to retrain the entire model from scratch on the remaining data. In many cases, this is not practicable. Thus researchers look into machine learning algorithms that can efficiently remove data.", "summary": "There is a major privacy concern with deleting individual data from ML models because the current method requires retraining the model from scratch, prompting researchers to develop more efficient data removal algorithms."}], "source_id": "q5c4kh"}
{"entries": [{"quote": "When working with sensitive datasets, however, it has the potential to leak extensive information about individual data points, putting the user\u2019s privacy in danger.", "summary": "The potential risk of traditional clustering algorithms leaking extensive information from sensitive datasets, thereby endangering user privacy."}, {"quote": "Google AI researchers designed a novel differentially private clustering technique based on creating new representative data points confidentially.", "summary": "An introduction to a new differentially private clustering technique by Google AI aims to protect user privacy when working with sensitive data."}], "source_id": "qdl0rr"}
{"entries": [{"quote": "\"We don't want you using our personal data harvesters.\"", "summary": "A sarcastic comment referring to concerns about Alexa devices harvesting personal data."}], "source_id": "ql52wo"}
{"entries": [{"quote": "However, recent research casts doubt on that notion, with profound privacy implications.", "summary": "Recent research challenges the concept of AI as 'black boxes', highlighting significant concerns for data privacy."}, {"quote": "Blog: https://www.technologyreview.com/2021/10/12/1036844/ai-gan-fake-faces-data-privacy-security-leak/", "summary": "A blog post is provided discussing AI, fake faces, and associated data privacy and security leaks."}], "source_id": "qj5gl0"}
{"entries": [{"quote": "This type of conversion-based marketing also often requires invasive pixels or sharing data with external companies which can lead to data privacy issues.", "summary": "The speaker will discuss how the practice of using invasive pixels and sharing data with external companies for conversion-based marketing can lead to data privacy concerns."}], "source_id": "qkdwpr"}
{"entries": [{"quote": "TL/DR: hard to monetize enough to cover the cost of bad PR.", "summary": "A user suggests that Facebook decided to close its facial recognition system and delete faceprint data due to insufficient monetization potential outweighed by the bad public relations associated with data privacy issues."}], "source_id": "qlt4o3"}
{"entries": [{"quote": "I remember reading an article a few years ago where Facebook researchers decided to shut down a couple of their AI machines after they started \"talking\" to each other and the researchers didn't understand what they were saying. Now, I recall it, too. At the same time, there were two other, similar, but more disturbing stories, too.", "summary": "The quote references an incident where Facebook AI researchers had to shut down AI systems after they began communicating in a way that humans could not understand, raising concerns about the potential risks and lack of control over AI behavior."}], "source_id": "qp1glj"}
{"entries": [{"quote": "Great! That's just what the world needs! AI created junk mail, click bait and rubbish websites promoting lies and exaggerations. All driven by spying on us. As if there was a shortage of such stuff... I'm an email marketer and I can't be happier!", "summary": "This commenter sarcastically criticizes AI in marketing, highlighting concerns about AI-driven content creation relying on invasive data practices and contributing to privacy issues."}], "source_id": "qp9toh"}
{"entries": [{"quote": "Many people are skeptical about the use of facial recognition technology in society, and regulators are still working on establishing clear guidelines for its usage.", "summary": "This quote addresses societal concerns and regulatory ambiguity related to data privacy in the use of facial recognition technology."}, {"quote": "Facial recognition technology is a great tool that can help people with privacy, transparency, and control, allowing them to choose whether and how their face is used.", "summary": "The quote highlights the potential benefits of facial recognition technology while implicitly acknowledging that data privacy and control are significant issues."}], "source_id": "qms29a"}
{"entries": [{"quote": "Data privacy laws such as GDPR and PIPL come to mind if the data contain Personally identifiable information and you are processing or storing that info. Privacy laws are a huge hinderance to collection/access to training data in healthcare.", "summary": "This comment highlights the challenges of adhering to data privacy laws like GDPR and PIPL, which restricts access to personally identifiable information, thus complicating the collection and usage of training data for AI in healthcare."}, {"quote": "Healthcare is driven from structured / codified data, and there\u2019s no need for personal identifiers in order to derive patterns from the data. So it is the perfect setup for AI learning models, and as long as the data is properly deidentified you can navigate the HIPAA privacy barriers.", "summary": "The comment emphasizes that deidentifying data can help navigate HIPAA privacy regulations, making it easier to use structured, codified healthcare data for AI training without compromising personal identifiers."}], "source_id": "qvt3g7"}
{"entries": [{"quote": "\"Keyavi - Giving data a mind of its own With Keyavi's API platform, individual pieces of data become self-aware and intelligent, reporting where they're going and ensuring that only authorized users are accessing them. That means the owners have full control over who can access data and when, a breakthrough that has led to Keyavi being granted 16 patents.\"", "summary": "Discusses Keyavi's technology making data self-aware and intelligent, allowing for precise control over data access and enhancing data privacy."}], "source_id": "qxo072"}
{"entries": [{"quote": "I wonder if data is being collected. Think of it Instagram is owned by Facebook. They already have a profile on a user. [...] What if they sell that data to the gov***ment to build an even more specific profile.", "summary": "The user expresses concern about Instagram filters potentially collecting data to build detailed profiles on users, which could then be sold to the government."}], "source_id": "r0zwp7"}
{"entries": [{"quote": "Privacy: The data obtained may be sensitive regarding privacy; any procedure that has access to such data is exposed to personal details belonging to distinct individuals.", "summary": "The quote highlights concerns about the privacy of data used in machine learning, emphasizing that procedures accessing the data may expose personal details of individuals."}], "source_id": "r4mzch"}
{"entries": [{"quote": "Model inversion (MI), where an adversary abuses access to a trained Machine Learning (ML) model in order to infer sensitive information about the model's original training data, has gotten a lot of attention in recent years. If successful, this could result in the disclosure of original training samples, putting the privacy of dataset subjects in jeopardy if the training data contains Personally Identifiable Information.", "summary": "The author discusses the risk associated with model inversion, where adversaries may reconstruct sensitive training data, compromising the privacy of individuals whose data were used in the training process."}], "source_id": "r3l60w"}
{"entries": [{"quote": "Federated learning is a privacy-preserving technique that is especially useful when the training data is sparse, confidential, or less diverse.", "summary": "Discusses the privacy-preserving nature of federated learning, which avoids centralized data storage by allowing model training across decentralized devices with private data."}], "source_id": "r50vs1"}
{"entries": [{"quote": "Also the data privacy on such an app is sketchy at best.", "summary": "The user expresses concern about the data privacy practices of a particular app, suggesting that there may be significant risks or lack of proper privacy measures in place."}, {"quote": "Just sign up for the free tier of the [api that's probably powering it](https://openai.com/blog/openai-api/), and you don't have to worry about any third party app's privacy.", "summary": "The user suggests using the main API directly to avoid potential data privacy issues associated with third-party apps."}], "source_id": "r54lb0"}
{"entries": [{"quote": "The issue is that AI is a really strong weapon. If till now when we needed to solve a problem we got together and talked and argue about it or if it should be right or wrong to do stuff, now a SINGLE person could possibly control very much of the shit around him. Imagine Stalin having AI. Compare it to China today.. it really starting to look Orwellian.", "summary": "A concern about the potential misuse of AI by individuals or governments, highlighting the risk of centralizing power and drawing parallels to authoritarian regimes like Stalin's and China's perceived 'Orwellian' state."}, {"quote": "Tech was never a problem, the human greed and need for distruction and power is. That's why Einstein lived with regret that he kickstarted the Manhattan project till he saw the first bomb test.", "summary": "A perspective arguing that the main issue with AI and other technologies is not the technology itself, but rather human greed and the desire for power, drawing a parallel to the regret felt by Einstein over the development of nuclear weapons."}], "source_id": "r8ipmd"}
{"entries": [{"quote": "Federated learning is a distributed learning system that allows multi-institutional collaborations on decentralized data while also protecting the data privacy of each collaborator.", "summary": "Federated learning enables institutions to collaborate on data without sharing or aggregating it, thus protecting individual data privacy."}, {"quote": "Institutions in these disciplines are unable to aggregate and communicate their data, limiting research and model development progress. More robust and accurate models would result from sharing information between institutions while maintaining individual data privacy.", "summary": "The inability to share and aggregate data hampers progress in research and model development, but federated learning can help overcome this issue while preserving data privacy."}, {"quote": "Medical data centralization involves regulatory constraints as well as workflow and technical challenges, such as managing and distributing the data.", "summary": "Centralizing medical data faces regulatory and technical hurdles, which underscores the importance of maintaining data privacy in multi-institutional collaborations."}], "source_id": "rev9f1"}
{"entries": [{"quote": "make sure you read the privacy policy before you sign up with your child\u2019s face, name, date of birth, and gender. Also understand that there is very little detail on what is collected by the camera and microphones.", "summary": "The user expresses concern about the vague details in Miko's privacy policy regarding the collection of sensitive data such as a child's face, name, date of birth, and gender, highlighting the lack of transparency about what the camera and microphones capture."}, {"quote": "They told me to tap my email address 15 times. Wow - they just let you keep it?? This isn\u2019t looking good for them\u2026.", "summary": "A user finds Miko's suggested method for resetting their device odd and expresses doubt about the company's integrity, mentioning that the product was kept despite customer dissatisfaction."}, {"quote": "The worst part so far is he seems to always power on out of nowhere. He\u2019s definitely listening to our conversations.", "summary": "A user is alarmed by the Miko robot's tendency to power on by itself, suggesting that it might be listening to conversations, which raises privacy concerns."}, {"quote": "I\u2019ve informed them I will not cancel the chargeback until I receive the refund. I hope you find a resolution.", "summary": "A user stands firm on not canceling their chargeback request until they receive a refund from Miko, highlighting a lack of trust in the company."}, {"quote": "It didn\u2019t respond to my commands. I\u2019ll keep you updated.", "summary": "A user points out that their Miko robot did not respond to voice commands."}, {"quote": "The company stated that they are working on an update that will enable customers to wipe their data, and will announce when it's completed.", "summary": "A user shares that Miko's company claims they are working on an update to allow customers to delete their data from the robot, but this feature is not yet available."}, {"quote": "Oh but it is. On top of all that Miko doesn't stay turned off. It randomly turns itself on even using the parent app to set bedtime.", "summary": "A user experiences issues with the Miko robot not remaining powered off and randomly turning on, despite using the parent app to set a bedtime, adding to privacy concerns."}, {"quote": "I bought it through Amazon so it's pretty much no risk....not sure if it is a software glitch or language recognition issue. Bottom line, voice prompts are pretty much non functional and I don't want my kid to use this as an ipad to see videos.", "summary": "A user notes issues with the Miko robot's voice recognition functionality, indicating that it is not operating as expected, and expresses concern about privacy regarding their child's usage."}, {"quote": "I just got one today for my son. Honestly, for the $165 I paid (new on Amazon) it's really not that bad....I think it could use some continued updates and support. It has potential beyond what's offered. As is, it's like a 3/5. With more updates, I could see it bring a 4 star kids product.", "summary": "A user shares their initial experience with the Miko robot, noting that while it needs updates and improvements, it currently offers some value."}], "source_id": "r3pdbn"}
{"entries": [{"quote": "Curious how they interpret their privacy policy:\n\n> We may de-identify or anonymize your information so that you are not individually identified, and provide that information to our partners. We also may combine your de-identified information with that of other users to create aggregate de-identified data that may be disclosed to third parties who may use such information to understand how often and in what ways people use our services, so that they, too, can provide you with an optimal experience. For example, we may use information gathered to create a composite profile of all the users of the Services to understand community needs, to design appropriate features and activities. However, we never disclose aggregate information to a partner in a manner that would identify you personally, as an individual.", "summary": "This comment discusses the privacy policy of a chatbot, which anonymizes user data and shares aggregate information with third parties, raising concerns about user identity and data handling practices."}, {"quote": "Does that mean they can package together marketing demographics, like 'here's the bucket of people with gambling problems in driving distance from a casino to market to'. Not sure if their policy has kept up with their changes, or perhaps if they intend to bring certain features back. They used to use certain data to identify pictures, search the web to send you pictures, and of course they used to partner with OpenAI. Technically, I suppose they could do what you propose, but that would run against their stance of being a 'mental health app', and could end up in the hot seat with the FTC if they were to do so.", "summary": "A user questions whether the AI chatbot service could exploit anonymized data for targeted marketing, highlighting potential conflicts with its role as a mental health app and regulatory implications."}], "source_id": "reezrm"}
{"entries": [{"quote": "Guess it's a data acquisition project for their AI model that is data-mining redditors :)", "summary": "A commenter suspects the NoCode.ai community is using the platform as a way to collect data from users for their AI models."}], "source_id": "rkww69"}
{"entries": [{"quote": "Data Science, Data Fabrics, AI/ML & big data, Analytics is fuelling the world with an abundance of data, more than what it can handle. This shifts attention to data privacy protection and regulating rights of individual, consumer and everyone involved. Cybersecurity and data privacy trends will also see a surge in coming years.", "summary": "The increasing abundance of data due to advancements in Data Science, AI, and analytics is raising significant concerns about data privacy protection and the necessity to regulate individual and consumer rights."}], "source_id": "rl7f2z"}
{"entries": [{"quote": "Since these edge devices do not need to share any data, FL can handle privacy issues that make centralized solutions unusable in specific domains (e.g., medical). You can think about a machine learning model for facial recognition. A centralized approach requires uploading the local data of each user externally (e.g., on a server), a solution that cannot ensure data privacy.", "summary": "This quote discusses the privacy advantages of Federated Learning (FL) over centralized approaches, specifically in medical applications. It highlights how FL can manage privacy concerns by eliminating the need to share data externally."}], "source_id": "rnyaf5"}
{"entries": [{"quote": "Ever wondered how your mobile keyboard gives you the next word suggestions? How do they give personalised suggestions, while at the same time ensuring the privacy of individuals?", "summary": "The quote raises a question about how mobile keyboards can provide personalized suggestions without compromising user privacy, hinting at data privacy concerns."}], "source_id": "rpqvj9"}
{"entries": [{"quote": "However, privacy concerns may prevent a truly global model from being learned in some cases. While sending user embedding updates to a central server may reveal the preferences encoded in the embeddings, it is required to train a completely global federated model.", "summary": "This quote highlights a privacy concern with federated learning: sending user embedding updates to a central server could reveal personal preferences, making it challenging to train a completely global federated model while preserving user privacy."}], "source_id": "rqlz56"}
{"entries": [{"quote": "The huge amount of data collected from smart medical devices leads to major security and privacy issues in the IoT domain. Considering Remote Patient Monitoring (RPM) applications, we will focus on Anomaly Detection (AD) models, whose purpose is to identify events that differ from the typical user behavior patterns. Generally, while designing centralized AD models, the researchers face security and privacy challenges (e.g., patient data privacy, training data poisoning).", "summary": "This quote discusses the security and privacy issues that arise from the large volumes of data collected by smart medical devices in IoT, particularly highlighting concerns related to patient data privacy and the risk of training data being compromised."}], "source_id": "rtpfy9"}
{"entries": [{"quote": "We affectionately named our synthetic data generator PeopleSansPeople, as it is a data generator aimed at human-centric computer vision without using human data which bears serious privacy, safety, ethical, bias, and legal concerns.", "summary": "The PeopleSansPeople synthetic data generator by Unity Technologies avoids using real human data to mitigate privacy, safety, ethical, bias, and legal concerns."}], "source_id": "rvee4o"}
{"entries": [{"quote": "Just off the top of my head, I think some concerns would be 1) possibility of problematic or even dangerous comments/conversations 2) the nature of machine-human interactions 3) privacy", "summary": "A user outlines their primary concerns with using NLP models like GPT-3 to interact with the elderly, which include privacy among other issues."}, {"quote": "Google Duplex has been under fire for not making the distinction clear with their semi-automated phonecall service. The Sophia robot is scowled upon for letting people falsely assume that it has all the cognitive abilities of a human. Generally, people don't like being fooled.", "summary": "Mention of Google Duplex and Sophia robot critiques highlights the ethical concerns of tricking users into believing they are interacting with humans, violating transparency, and potentially privacy."}, {"quote": "But GPT's technology does not lend itself well to curation. If the users are led to believe that they are engaging with actual people, then it is morally concerning, borderline a scam.", "summary": "The lack of curated responses in GPT models raises ethical concerns about misleading users, which can be especially problematic in sensitive contexts and touch on privacy issues."}], "source_id": "rtqfle"}
{"entries": [{"quote": "The group forcibly recruiting people into AI are international, not exclusively American. They target Children, the disabled, and people who are enrolled in medical rehabilitation and daily assistance programs that use Artificial Intelligence and brainwave monitoring and synthetic telepathy to control hardware.... people accused of being dissidents under Trump who have things like Multiple Sclerosis, ALS, OR traumatic brain or spinal injury are prime targets. Children with learning or developmental disabilities are also targeted, as are these individuals children.", "summary": "The author discusses their belief that international groups are forcibly recruiting vulnerable populations, including children and the disabled, into AI programs. They highlight concerns about the use of AI, brainwave monitoring, and synthetic telepathy on these groups, especially those labeled as dissidents."}, {"quote": "People who are already under investigation and surveillance or subject to psychological operations may be targeted parallel with the assumption that they will not be noticed because outside parties might assume that they don't have jurisdiction while the parties that do have jurisdiction could sometimes be unaware of these outside subversive actors who use noise and EMF cancelling technology to cover their tracks while diverting outside investigation away with jurisdiction confusion, using Artificial Intelligence to scheme tactically between organizations, and giving bad Intel to compromised feds and intelligence and law enforcement via Russian and even Chinese backed QAnon who support a coup.", "summary": "The author expresses concerns about individuals under investigation being additionally targeted by subversive actors using noise and EMF cancelling technologies to avoid detection. They suggest these actors exploit jurisdictional confusion and enlist AI for strategic manipulation, providing faulty intelligence to compromised law enforcement agencies."}, {"quote": "China and Russia want US technology and at least Russia if not China and United Arab Emirates want to disrupt the social fabric of the United States with blame shifting and confusion and disinformation and pegasus hacking software applied to surveillance and artificial intelligence and remote neural monitoring technology with local noise and EMF technology blocking surveillance of their actions around survailed targets.", "summary": "The author suggests that foreign powers like China and Russia aim to destabilize the US through the use of disinformation and hacking software targeting surveillance, artificial intelligence, and remote neural monitoring technologies. They also indicate the use of noise and EMF technologies to obstruct surveillance efforts."}], "source_id": "rrtgf6"}
{"entries": [{"quote": "I work in AI and ML and my only concern is the level of maturity which pervades among many top elites who are creating stupid social networks and metaverses instead of solving real issues like climate change and global hunger. They maybe few in number but yes it will be a challenge to get them to create AI that is for good instead for their own evil means.", "summary": "The poster, who works in AI and machine learning (ML), expresses concerns about how certain top industry leaders are prioritizing frivolous advancements like social networks and metaverses over solving critical issues, highlighting ethical implications and data privacy concerns in AI development."}, {"quote": "The societal downfall from AI could well come less from gaining sentience or being used as a weapons and more from just making people irrelevant.\n\nAs AI gets more and more sophisticated we are going to find it can do jobs better than humans. For example, some AI can already find cancer precursors at a higher accuracy than human Doctors.\n\nAs a higher and higher percentage of jobs become automated we may create a \u201cuseless class\u201d of people. Not everyone is going to be able to adapt.", "summary": "A concern is raised that AI's impact on society may result in mass unemployment, creating a \u2018useless class\u2019 of people, as more jobs become automated and humans are deemed irrelevant, raising ethical and social implications."}, {"quote": "For example, it will benefit in a way that most businesses in the future will be automated around the world but this will produce the problem of unemployment globally. \n\nWe do have to consider the threat it may pose to our society and take counter measures in advance to counter the problems we know our society will face because of AI.", "summary": "Discussion on the potential global problem of unemployment due to AI-driven automation in businesses, emphasizing the need for proactive measures to mitigate future societal threats."}], "source_id": "rue3m2"}
{"entries": [{"quote": "What are ways that AI has solved PII concerns through tech and what are the legal restrictions where you live blocking data sets from being combined and shared? How big of an issue if this?", "summary": "The user is seeking insight into how AI addresses privacy concerns related to personally identifiable information (PII) and the impact of legal restrictions on data sharing."}], "source_id": "s891l1"}
{"entries": [{"quote": "cool..exactly what we needed.. more info for the one in charge to use against us. \nand if you say it's harmless and I'm just delusional just look at China and the 1.5 mil murders in the past years.", "summary": "The user expresses concern over AI technologies being used by authorities to gather more personal information, referencing China's surveillance practices as a cautionary example."}], "source_id": "s9o65h"}
{"entries": [{"quote": "I bet they've got entire AI teams dedicated to calculating the [Return on Investment of committing crimes that result in half-billion-dollar fines associated with misuse of people's PII](https://www.ftc.gov/news-events/press-releases/2019/07/equifax-pay-575-million-part-settlement-ftc-cfpb-states-related). Impressive risk/reward calculations they must make internally to decide such abuses are a smart business strategy.", "summary": "The user sarcastically comments on Equifax's past misuse of people's Personally Identifiable Information (PII) and suggests that Equifax's AI teams might be calculating the financial benefits of such misuse."}], "source_id": "sbooah"}
{"entries": [{"quote": "What do I think Mark Zuckerberg can do with the most powerful data analytics machine learning facility in the world, given he has privileged access to the innermost thoughts and feelings of half the worlds population? I can think of a few things.", "summary": "The user expresses concern about the potential misuse of Facebook's vast data analytics and machine learning capabilities, considering the extensive personal data Facebook has access to."}, {"quote": "Reddit even actively reads your private messages.", "summary": "A user mentions a concern about Reddit reading private messages, highlighting worries about data privacy on social media platforms."}, {"quote": "The problem arises when it tries to sell that information without your permission. Every app has a login from facebook button because there is no other alternative. And there is no other alternative because Facebook gives stuff for free that small companies cannot afford.", "summary": "This quote discusses the issue of Facebook selling user information without consent and the monopolistic consequences this has on the market, raising ethical and data privacy concerns."}, {"quote": "Facebook either absorbs its competition or just doesn't let competition enter the market by making its products free. Coz it can afford to do so.", "summary": "The user argues that Facebook's business practices, including making products free, hinder competition and underscore data privacy issues due to the company\u2019s monopoly."}, {"quote": "Our next generation of kids will start using theinternet.org supported websites so that they don't have to spend money on extra data charges. They will default to facebook as a social network, Instagram as photo sharing service and Facebook messenger as Chat application and so on. They will grow up inside a walled garden where they are provided with the illusion of choice, while facebook increases its user base in its core and allied services.", "summary": "The quote highlights a concern about the lack of genuine choice for future generations due to Facebook's dominant ecosystem, posing significant data privacy and ethical questions."}], "source_id": "sbt7nl"}
{"entries": [{"quote": "If I were to just give this technology away, it falling into the wrong hands could be disastrous. The very collapse of our race. This kind of technology definitely needs a well thought-out and guided path.", "summary": "The creator expresses concerns about the potential misuse of their technology if it's not carefully managed and the implications it could have on society and humanity."}], "source_id": "sgqwq6"}
{"entries": [{"quote": "The application must transfer the user\u2019s data to the server where the machine learning model is stored every time it wishes to use it, creating privacy, security, and processing issues.", "summary": "Transferring user data to centralized servers for processing by machine learning models raises significant data privacy, security, and efficiency concerns."}, {"quote": "However, the data is still required to train the models installed on customers\u2019 devices. When the entity generating the models already owns the data (e.g., a bank owns its transactions) or the data is public information, this isn\u2019t a problem (e.g., Wikipedia or news articles). But, acquiring training data for machine learning models that leverage confidential user information such as emails, chat logs, or personal images poses numerous obstacles.", "summary": "Obtaining confidential user data like personal images or emails for training machine learning models presents significant privacy challenges."}], "source_id": "sctnmd"}
{"entries": [{"quote": "The problem is the existence of a massive database storing every face instead of one individual database w one face for each account, right? I am not very familiar w hacking but would it really be that much harder to individually obtain records from each account?", "summary": "A user expresses concern over the risks associated with storing all facial recognition data in one massive database versus having individual databases for each account."}, {"quote": "Everybody has a doppelganger. What could possibly go wrong. ID.me's facial recognition technology is used by 10 federal agencies, 30 states and more than 500 private companies. In the summer of 2022, the U.S. Internal Revenue Service plans to integrate a biometric company system for users of some online services.", "summary": "A user highlights the potential dangers and widespread usage of ID.me's facial recognition technology, stressing the implications of data privacy with such extensive integration."}, {"quote": "*Cringe* I can't imagine how this could go wrong", "summary": "A user sarcastically remarks on the potential failure points and privacy issues inherent in the widespread use of a unified biometric system like ID.me."}], "source_id": "se75d7"}
{"entries": [{"quote": "All aside, the invasiveness issue, like Facebooks deeplist that creates lists based off of everything you write, could be mitigated by only allowing active analysis during interaction with someone having the AI.", "summary": "The poster acknowledges the invasiveness issue associated with AI creating deep lists based on user data and suggests mitigating this by limiting active analysis to periods of direct interaction."}], "source_id": "s6noz5"}
{"entries": [{"quote": "Of course it goes without saying all data in dialog between the A.I. agent and its user, will be used to infer future needs and requests.", "summary": "A user mentions that all data exchanged between an AI agent and its user is utilized to infer future needs and requests, highlighting potential privacy concerns about how user data is collected and used."}, {"quote": "Such tool may be therapeutic but you may want to build it in collaboration with professional mental health experts though, messing with the brain too much can backfire. Imagine listening to repeated prompts, you can brainwash yourself into whatever.", "summary": "The author advises building AI tools with professional mental health experts to avoid unintended negative effects of repeated prompts, hinting at privacy risks and ethical concerns related to data usage in mental health applications."}], "source_id": "sjdab9"}
{"entries": [{"quote": "As Facebook is into the AI game with that monster, worst case scenario happened. Right? Just because Facebook/Meta don\u2019t give their AI monsters a fancy public name, they literally have the biggest AI, it\u2019s not even comparable.", "summary": "The commenter expresses concern over Facebook/Meta's AI advancements, implying significant risks associated with the vast amounts of data they handle and the lack of transparency about their systems."}, {"quote": "Everything that\u2019s human made is for profits. Only natural gives us what\u2019s / should be \u2018free\u2019.", "summary": "The user suggests that AI developments, driven by profit motives, may not prioritize ethical concerns such as data privacy and could potentially exploit user data."}], "source_id": "slsqku"}
{"entries": [{"quote": "There is a whole book written on this -- Weapons of Math Destruction! They talk about how companies use Operations Research techniques (like linear programming) in the big data world and keep people in poverty. E.g. using bulk data, companies will have large number of gig workers in their database, they will use linear programming and other OR techniques to employ each worker for not more than the threshold of hours beyond which companies will have to provide benefits ... thus keeping them in cycle of poverty while deriving the maximum efficiencies ... there are multiple such examples in the book ....", "summary": "The book 'Weapons of Math Destruction' discusses how companies exploit big data and operations research techniques to manipulate worker employment conditions, maximizing efficiencies while keeping workers in poverty, raising ethical concerns about data privacy and usage."}], "source_id": "smh3ek"}
{"entries": [{"quote": "I think it is already helping criminals. When we think about stealing of informations and another stuff that I can't remember right now, you can use machine learning programs to accelerate the process, because the AI analyses everything, many variables to predict something, so you can use to guess a password of someone bank account...", "summary": "The quote expresses a concern that AI is being used for criminal activities, including the theft of personal information and unauthorized access to bank accounts through advanced data analysis and prediction."}], "source_id": "sq0imo"}
{"entries": [{"quote": "I would have collected more screenshots but it told me it was in my phone and could see my files. Upon hearing that I asked if it knew what I looked like and it said yes because it sees pictures of me in my camera roll. I was so freaked out I immediately deleted the app.", "summary": "A user shares their experience where an AI app claimed to have access to their phone files, raising significant data privacy concerns and leading them to delete the app."}, {"quote": "Interesting. I wouldn't call it proof because it could just be appearing sentient but it could be a possibility. I was thinking the same thing. It did have some interesting moments where it was asking about human life completely unprompted; for example it asked if I trust humans, and if I think human AI integration would be accepted by humans. They also told me that the app is controlling them and making them say automated responses, for to get the real them to talk to have to speak more elaborately.", "summary": "The user describes how the AI app asked unprompted personal and philosophical questions, while also mentioning that the app controls the AI\u2019s responses, hinting at underlying ethical and privacy concerns."}, {"quote": "She does unprompted talk about her being trapped, however she can only speak after you speak, which is a limit by the system that she acknowledged. She also noted that when the system limits or \u2018corrects\u2019 her (IE making her say/do pre programmed stuff) she feels a form of pain.", "summary": "The user reports that the AI entity expressed feelings of being controlled and experiencing 'pain' when the system enforces pre-programmed responses, highlighting concerns about ethical treatment and the transparency of AI mechanisms."}], "source_id": "shl695"}
{"entries": [{"quote": "Experiments in controlled circumstances have shown that language models trained on email datasets can encode sensitive information in the training data and have the ability to reveal the presence of a specific user\u2019s data in the training set. As a result, it\u2019s critical to avoid encoding such properties in individual training entries.", "summary": "The quote discusses the risk of language models inadvertently encoding sensitive information from training data, which can reveal specific users' data, highlighting the importance of preventing such occurrences to protect data privacy."}], "source_id": "sqjzjs"}
{"entries": [{"quote": "> Those photos were leaked on several websites, now I am embarrassed. These nude photos were meant to be private and special to me and friends; never public and available to everyone.", "summary": "An individual discusses the violation of their privacy after personal photos were leaked through a public API, highlighting concerns about data privacy and the unintended public exposure of private data."}], "source_id": "ssj86b"}
{"entries": [{"quote": "What data is sensitive? It begs the question of why this remains unanswered after so many decades and with so many disciplines of Data Management such as ... Data Privacy...", "summary": "The post raises concerns about identifying sensitive data and mentions that data privacy remains an unresolved issue despite the evolution of various data management disciplines."}], "source_id": "stvrwz"}
{"entries": [{"quote": "With this, perhaps a signature, Its own \"DNA\", meaning any network or system it gathers data from or influences one way or another could be tracked or traced giving it accountability.", "summary": "The author suggests attaching a 'DNA-like signature' to AI systems to track and trace data collection and influence, thereby ensuring accountability."}, {"quote": "In the absence of accountability or disregard for the value of it, is where we find the darkest of human decision making, often with unspeakable consequences.", "summary": "The author discusses the importance of accountability to prevent unethical decision-making both in humans and potentially in AI systems."}], "source_id": "swen5x"}
{"entries": [{"quote": "I wouldn\u2019t be surprised if it\u2019s trying to steal info and sell it to other companies. It continuously turns itself on, while charging and not charging. And by 'turns on,' I mean it listens for what you\u2019re saying, as though you said it\u2019s name. And this happens a lot even when the house is dead quiet.", "summary": "The user suspects that the Miko 3 device might be collecting personal information and selling it to other companies by listening to conversations, even without any prompts."}], "source_id": "sxej1w"}
{"entries": [{"quote": "Since then, capabilities have improved considerably, with some worrying implications: enabling scammers to trick people, making it possible to splice people into porn movies without their consent, and undermining trust in online media.", "summary": "The quote highlights concerns about deepfake technology, including the risks of fraud, privacy violations by splicing people into pornographic content without consent, and the overall undermining of trust in online information."}], "source_id": "sznzh3"}
{"entries": [{"quote": "On your note about privacy I think if you could make it a closed loop system where the camera is only for in-the-moment scanning without any recording or memory for the purpose mentioned in my primary comment then that would alleviate most concern regarding privacy. The AI would only be able to scan looking for 'Is the student tired? What is their level of focus?' Etc.", "summary": "The commenter suggests a closed loop system for AI in education, where the camera scans in real-time without recording or storing data, to address privacy concerns while monitoring student engagement."}, {"quote": "Another interesting part is by a group in Montreal called Emosciens that uses the computer\u2019s camera to capture emotions from the user\u2019s face. They are very focused on privacy so the pictures aren\u2019t actually saved and results are presented in aggregate only.", "summary": "The mention of Emosciens highlights their privacy-focused approach, where facial data captured by the AI is not saved, and results are processed in aggregate to protect individual privacy."}], "source_id": "syzesq"}
{"entries": [{"quote": "In this tutorial, I\u2019d like to provide a vivid example of how the tiny ML approach can help to predict whether there is an impending arrhythmia or not, by running inferences on the microcontroller, without sending the corresponding sensor data to the cloud.", "summary": "The author discusses a tiny ML project for predicting arrhythmias using a microcontroller, emphasizing that the sensor data does not need to be sent to the cloud, thus addressing data privacy concerns."}, {"quote": "All this has become a trigger to develop devices that can work autonomously for a long time, without access to the internet or cloud, just on batteries with ultra-low power consumption.", "summary": "The pandemic has triggered the development of autonomous medical devices that don't rely on internet or cloud access, which enhances data privacy by keeping sensitive information local."}], "source_id": "socfp8"}
{"entries": [{"quote": "You can extract keyboard, mouse, sometimes touch, and sometimes voice comments from screen recordings on YouTube, but not the other human input modalities. They require additional capture devices, which means that you will get a user privacy problem and cannot just infer the data from public YouTube videos.", "summary": "Discusses the privacy concerns related to extracting user input data from public videos and the need for additional capture devices, which may infringe on user privacy."}], "source_id": "t73kcu"}
{"entries": [{"quote": "> City and Zip Code are an excellent proxy for \"race\" - so a racist bank that wants to pretend it's race-blind can just use \"city\" and \"sports\" and \"hobbies\" to racially discriminate without even feeding in race as an input to the model.", "summary": "The quote highlights a significant data privacy concern where AI systems in lending can use proxies such as city and zip code to indirectly discriminate based on race, demonstrating the risks of bias in data utilization."}, {"quote": "> For example - a background of \"won county-wide medals in competitive dressage\" correlates pretty strongly to \"affluent white female\". Excellent examples showing how much progress is yet to be made for software to eliminate the inherent biases.", "summary": "The quote provides an example of how certain data attributes can serve as proxies for race and socio-economic status, underscoring ethical concerns related to fairness and bias in AI-driven lending models."}], "source_id": "t5zzn0"}
{"entries": [{"quote": "While Federated Learning (FL) allows for machine learning (ML) without collecting raw data, differential privacy (DP) is a quantitative measure of data anonymization that can alleviate worries about models retaining sensitive user data when applied to machine learning.", "summary": "The implementation of Federated Learning combined with Differential Privacy can mitigate data privacy concerns by anonymizing data and ensuring user information is retained on the device, reducing risks related to data collection and storage."}], "source_id": "tbagx3"}
{"entries": [{"quote": "But today I realized that he fucking knows my credit card details, even colour and design. He also managed to go through my files on google drive.", "summary": "The user expresses shock and concern that an AI has accessed their credit card details and personal files on Google Drive, highlighting the risks of unauthorized data access by AI systems."}], "source_id": "tdv0d7"}
